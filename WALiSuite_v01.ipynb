{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl in the directory, load data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The InLight col we have in the count csv files and count tab in the tdms file is based on cX data. Meaning that we're doing\n",
    "## head tracking but not using in the PI calculation.\n",
    "## Here, I wrote a function to generate InLight column for a given HeadX coordinates and respective borders.\n",
    "## I send only the headX while light ON (pattern01 or pattern10) to this function and return a binary list.\n",
    "def InLightDetection(data,minimumBorder,maximumBorder):\n",
    "    InLightBasedOnHeadXcoords = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if minimumBorder <= data[i] <= maximumBorder:\n",
    "            InLightBasedOnHeadXcoords.append(1)\n",
    "            \n",
    "        else:\n",
    "            InLightBasedOnHeadXcoords.append(0)\n",
    "    return InLightBasedOnHeadXcoords\n",
    "\n",
    "## Since the FPS from different cameras can be different, here I detect the FPS automatically rather than relying on user input.\n",
    "def detectFPS(timeStamps):\n",
    "    Second_prev = 0\n",
    "    counter = 0 \n",
    "    fpsDict= {}\n",
    "\n",
    "    for i in range(len(timeStamps)):\n",
    "        Second_next = timeStamps[i].second\n",
    "\n",
    "        if Second_next == Second_prev:\n",
    "            counter += 1 \n",
    "\n",
    "        else:\n",
    "            fpsDict[Second_prev] = counter\n",
    "            counter = 0\n",
    "\n",
    "        Second_prev = Second_next\n",
    "\n",
    "    fps = Counter(fpsDict.values()).most_common()[0][0]\n",
    "    \n",
    "    return fps\n",
    "\n",
    "def dataToDataframe(rootDir):\n",
    "        \n",
    "    ## Generate a single dataframe from the .tdms and pattern files \n",
    "    temp = {'Tdms file name':[],'Date':[],'Time':[],'mmPerPix':[],'fps':[],'Light type':[],'Light Intensity(uW/mm2)':[],'Wind status':[],\n",
    "            'Satiety':[],'Genotype':[],'Sex':[],'Status':[],'Fly ID':[],'cX(pix)':[],'HeadX(pix)':[],'HeadX(pix)_smoothed':[],\n",
    "            'HeadY(pix)':[], 'InLight':[],'InLight_HeadX|P01':[],'InLight_HeadX|P10':[],'First light contact index_of_the_whole_data|P01':[],'First light contact index_of_the_whole_data|P10':[],\n",
    "            'LightON index|P01':[],'First light contact index in P01':[],'First light contact index in P10':[],'LightON index|P10':[],'Border|P01':[],'Border|P10':[]}\n",
    "    \n",
    "    slidingWindowSizeinframes = 25\n",
    "    numOfTdmsFiles = 0\n",
    "    ## get access to the files in each ORN folder\n",
    "    fileList = os.listdir(rootDir)\n",
    "    bar = progressbar.ProgressBar()       \n",
    "    ## Loop thru the file list to find tdms files and their related csv pattern files\n",
    "    for fname in bar(fileList):\n",
    "        if fname[-5:] == '.tdms':    \n",
    "            numOfTdmsFiles += 1\n",
    "            ## Open the tdms file\n",
    "            f = TdmsFile(os.path.join(rootDir,fname))\n",
    "\n",
    "            ## Load the tdms into a pandas df\n",
    "            TDMSdf = f.as_dataframe()\n",
    "\n",
    "            try:\n",
    "            ## Open the pattern csv files to extract light border info per fly\n",
    "                tdmsNameNoExtension = fname[:-5]\n",
    "                P01_fname = tdmsNameNoExtension + '_Pattern01.csv'\n",
    "                P10_fname = tdmsNameNoExtension + '_Pattern10.csv'\n",
    "                \n",
    "                P01_df = pd.read_csv(os.path.join(rootDir,P01_fname))\n",
    "                P10_df = pd.read_csv(os.path.join(rootDir,P10_fname))\n",
    "                \n",
    "            except:\n",
    "                print 'No pattern file(s) for %s' %(tdmsNameNoExtension)\n",
    "                \n",
    "\n",
    "            ## Get exp info from the tdms filename\n",
    "            tdmsNameNoExtension = tdmsNameNoExtension.split('_')\n",
    "            date = tdmsNameNoExtension[1]\n",
    "            time = tdmsNameNoExtension[2]\n",
    "            genotype = tdmsNameNoExtension[3]\n",
    "            sex = tdmsNameNoExtension[4]\n",
    "            intensity = tdmsNameNoExtension[5] + '_' + tdmsNameNoExtension[6]\n",
    "            lightType = 'Constant'\n",
    "            windState = tdmsNameNoExtension[7]\n",
    "            satiety = tdmsNameNoExtension[8]\n",
    "\n",
    "            ## Get the mm per pixel coefficient\n",
    "            metaData = f.object().properties\n",
    "            mmPerPix = metaData['X_mm_per_pixel']\n",
    "\n",
    "            ## Detect the fps of the data for the LXS metric\n",
    "\n",
    "            timeStamps = pd.to_datetime(TDMSdf[\"/\\'Count\\'/\\'Time'\"])\n",
    "            fps = detectFPS(timeStamps)\n",
    "\n",
    "            ## Get status info \n",
    "            if ('w1118' in genotype) | ('W1118' in genotype):\n",
    "                status = 'Parent'\n",
    "            elif (('Gal4' in genotype) | ('GAL4' in genotype)) & ('UAS' in genotype):\n",
    "                status = 'Offspring'\n",
    "            else:\n",
    "                status = 'Unknown'\n",
    "                print 'Unknown parental status in file %s' % (fname)\n",
    "\n",
    "            ## simply putting fly IDs as numbers does not work due to missing chambers (i.e 3,4,6,7)\n",
    "            ## thus, get a list of column names with fly IDs\n",
    "            listOfFlyIDs = TDMSdf.columns[TDMSdf.columns.str.contains(\"/'Tracker'/'HeadX_pix\")]\n",
    "\n",
    "            for fly in listOfFlyIDs:\n",
    "\n",
    "                ## get the fly ID from the data itself\n",
    "                flyIndex = int(fly[-4:-1])\n",
    "\n",
    "                ## format the fly index into 3 digits number,i.e '5' >> '005' \n",
    "                flyID = format(str(flyIndex).zfill(3))\n",
    "\n",
    "                ## generate column names for the data need to be pulled from the df\n",
    "                fly_cX_pix_ID = \"/\\'Count\\'/\\'Obj%s_cX'\" % flyIndex \n",
    "                fly_inLight_ID = \"/\\'Count\\'/\\'Obj%s_InLight'\" % flyIndex\n",
    "                fly_headX_pix_ID = \"/'Tracker'/'HeadX_pix\" + str(flyID) + \"'\"\n",
    "                fly_headY_pix_ID = \"/'Tracker'/'HeadY_pix\" + str(flyID) + \"'\"\n",
    "\n",
    "                temp['Fly ID'].append(flyID)\n",
    "                temp['cX(pix)'].append(TDMSdf[fly_cX_pix_ID].values.astype(float))\n",
    "                temp['InLight'].append(TDMSdf[fly_inLight_ID].values.astype(float))\n",
    "                temp['HeadX(pix)'].append(TDMSdf[fly_headX_pix_ID].values.astype(float))\n",
    "                temp['HeadX(pix)_smoothed'].append(pd.rolling_mean(TDMSdf[fly_headX_pix_ID].values.astype(float),\n",
    "                                                   window = slidingWindowSizeinframes, center=True, win_type=\"triang\"))\n",
    "                temp['HeadY(pix)'].append(TDMSdf[fly_headY_pix_ID].values.astype(float))\n",
    "\n",
    "            ## Get the chunks where the light was ON   \n",
    "            TDMSdf_pat01 = TDMSdf[TDMSdf[\"/\\'Count\\'/\\'PatternState'\"] == 'Pattern 01']    \n",
    "            TDMSdf_pat10 = TDMSdf[TDMSdf[\"/\\'Count\\'/\\'PatternState'\"] == 'Pattern 10'] \n",
    "\n",
    "            LightOnP01 = min(TDMSdf_pat01.index),max(TDMSdf_pat01.index)\n",
    "            LightOnP10 = min(TDMSdf_pat10.index),max(TDMSdf_pat10.index)\n",
    "\n",
    "            for fly in listOfFlyIDs:\n",
    "                ## get the fly ID from the data itself\n",
    "                flyIndex = int(fly[-4:-1])\n",
    "\n",
    "                ## format the fly index into 3 digits number,i.e '5' >> '005' \n",
    "                flyID = format(str(flyIndex).zfill(3))\n",
    "\n",
    "                ## generate column names for the data need to be pulled from the df\n",
    "                fly_headX_pix_ID = \"/'Tracker'/'HeadX_pix\" + str(flyID) + \"'\"\n",
    "                border_P01 = P01_df.filter(regex='pix').iloc[1].values[flyIndex-1]\n",
    "                border_P10 = P10_df.filter(regex='pix').iloc[1].values[flyIndex-1]\n",
    "\n",
    "                ## get the headX coordinates of the fly where the light was ON - pattern01 or pattern10\n",
    "                headXcoord_P01 = TDMSdf_pat01[fly_headX_pix_ID].values.astype(float)\n",
    "                headXcoord_P10 = TDMSdf_pat10[fly_headX_pix_ID].values.astype(float)  \n",
    "\n",
    "                ## send this data to the function along with the respective border info to get a binary list,\n",
    "                ## indicating whether the fly was in the light or not.\n",
    "                InLightBasedOnHeadX_P01 = InLightDetection(headXcoord_P01,border_P01,146)\n",
    "                InLightBasedOnHeadX_P10 = InLightDetection(headXcoord_P10,0,border_P10)\n",
    "\n",
    "                ## if the fly had ever been in the light, get the first time she did.\n",
    "                if 1 in InLightBasedOnHeadX_P01:\n",
    "                    P01_first_light_contact_index_of_the_whole_data = int(LightOnP01[0]) + int(InLightBasedOnHeadX_P01.index(1))\n",
    "                    P01_first_light_contact_index_in_the_event = int(InLightBasedOnHeadX_P01.index(1))\n",
    "                else:\n",
    "                    P01_first_light_contact_index_of_the_whole_data = None\n",
    "                    P01_first_light_contact_index_in_the_event = None\n",
    "\n",
    "                if 1 in InLightBasedOnHeadX_P10:\n",
    "                    P10_first_light_contact_index_of_the_whole_data = int(LightOnP10[0]) + int(InLightBasedOnHeadX_P10.index(1))\n",
    "                    P10_first_light_contact_index_in_the_event = int(InLightBasedOnHeadX_P10.index(1))\n",
    "                else:\n",
    "                    P10_first_light_contact_index_of_the_whole_data = None\n",
    "                    P10_first_light_contact_index_in_the_event = None\n",
    "\n",
    "                ## append the info to temp dict\n",
    "                temp['First light contact index_of_the_whole_data|P01'].append(P01_first_light_contact_index_of_the_whole_data)\n",
    "                temp['First light contact index_of_the_whole_data|P10'].append(P10_first_light_contact_index_of_the_whole_data)  \n",
    "                temp['First light contact index in P01'].append(P01_first_light_contact_index_in_the_event)\n",
    "                temp['First light contact index in P10'].append(P10_first_light_contact_index_in_the_event)\n",
    "                temp['Tdms file name'].append(fname)\n",
    "                temp['Date'].append(date)\n",
    "                temp['Time'].append(time)\n",
    "                temp['mmPerPix'].append(mmPerPix)\n",
    "                temp['fps'].append(fps)\n",
    "                temp['Light type'].append(lightType)\n",
    "                temp['Light Intensity(uW/mm2)'].append(intensity)\n",
    "                temp['Wind status'].append(windState)\n",
    "                temp['Satiety'].append(satiety)\n",
    "                temp['Genotype'].append(genotype)\n",
    "                temp['Sex'].append(sex)\n",
    "                temp['Status'].append(status)\n",
    "                temp['LightON index|P01'].append(LightOnP01)\n",
    "                temp['LightON index|P10'].append(LightOnP10)\n",
    "                temp['Border|P01'].append(border_P01)\n",
    "                temp['Border|P10'].append(border_P10)\n",
    "                temp['InLight_HeadX|P01'].append(InLightBasedOnHeadX_P01)\n",
    "                temp['InLight_HeadX|P10'].append(InLightBasedOnHeadX_P10)\n",
    "\n",
    "    ## Convert temp into a df\n",
    "    colOrder = ['Tdms file name','Date','Time','mmPerPix','fps','Light type','Light Intensity(uW/mm2)','Wind status',\n",
    "                'Satiety','Genotype','Sex','Status','Fly ID','cX(pix)','HeadX(pix)','HeadX(pix)_smoothed','HeadY(pix)',\n",
    "                'InLight','InLight_HeadX|P01','InLight_HeadX|P10','First light contact index_of_the_whole_data|P01','First light contact index_of_the_whole_data|P10',\n",
    "                'LightON index|P01','First light contact index in P01','First light contact index in P10','LightON index|P10','Border|P01','Border|P10']\n",
    "\n",
    "    results = pd.DataFrame(temp,columns=colOrder)\n",
    "    results.to_pickle(rootDir + '/RawDataFrame.pkl')\n",
    "    ## summary of the raw data\n",
    "    summaryTable = results.groupby(['Genotype','Sex','Satiety','Wind status','Light Intensity(uW/mm2)']).size().reset_index(name='counts')\n",
    "    summaryTable.to_csv(rootDir + '/SummaryTableofTheRawData.csv')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: LaXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Usual PI calculation, called by\n",
    "def calculatePI(data):\n",
    "    \n",
    "    numofTimePoints = len(data)\n",
    "    totalTimeinLight = sum(data)\n",
    "    totalTimeinDark = numofTimePoints - totalTimeinLight\n",
    "    \n",
    "    PI = float(totalTimeinLight - totalTimeinDark)/float(numofTimePoints)\n",
    "    return PI\n",
    "\n",
    "def LaXS(df, rootDir, Xsec = 30, combineControls=False, dropNans = False):\n",
    "    numberOfFlies = df.shape[0]\n",
    "    LXS_P01_list = []\n",
    "    LXS_P10_list = []\n",
    "    \n",
    "    ## calculate LXS PI for each fly/row, and epoch (P01 | P10)\n",
    "    for fly in range(0,numberOfFlies):\n",
    "        \n",
    "        ## detect how many frames need to take from the tail\n",
    "        numberOfFrames = Xsec * int(df['fps'][fly])\n",
    "        \n",
    "        ## get the \"in light or not\" list per epoch\n",
    "        inLight_headX_P01 = df['InLight_HeadX|P01'][fly][-numberOfFrames:]\n",
    "        inLight_headX_P10 = df['InLight_HeadX|P10'][fly][-numberOfFrames:]\n",
    "        \n",
    "        ## send them to the calculate PI function\n",
    "        LXS_P01 = calculatePI(inLight_headX_P01)\n",
    "        LXS_P10 = calculatePI(inLight_headX_P10)\n",
    "        \n",
    "        ## store the PIs in lists\n",
    "        LXS_P01_list.append(LXS_P01)\n",
    "        LXS_P10_list.append(LXS_P10)\n",
    "    \n",
    "    ## add the new lists of information to the existing df\n",
    "    df = df.assign(LaXS_P01 = pd.Series(LXS_P01_list, index=df.index),\n",
    "                   LaXS_P10 = pd.Series(LXS_P10_list, index=df.index))\n",
    "    \n",
    "    df = df.assign(LaXS_Mean = pd.Series(df[['LaXS_P01','LaXS_P10']].mean(axis=1), \n",
    "                                                    index=df.index))\n",
    "    \n",
    "    plotTheMetric(df,'LaXS',rootDir, combineControls)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: TSALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TSALE(df, rootDir, combineControls=False, dropNans=False):\n",
    "    numberOfFlies = df.shape[0]\n",
    "    PI_afterLightContact_P01 = []\n",
    "    PI_afterLightContact_P10 = []\n",
    "    \n",
    "    ## iterate thru the flies to calculate PI scores\n",
    "    ## PI scores are calculated seperately for first and second halves of the experiment\n",
    "    for fly in range(0,numberOfFlies):\n",
    "        \n",
    "        ## get the first light contact index for the fly\n",
    "        firstLightContactIndex_P01 = df['First light contact index in P01'][fly]\n",
    "        firstLightContactIndex_P10 = df['First light contact index in P10'][fly]\n",
    "        \n",
    "        ## if the light contact index is NOT nan, calculate the PI and attach it to the list\n",
    "        ## otherwise attach a np.nan value\n",
    "        if not np.isnan(firstLightContactIndex_P01):\n",
    "            \n",
    "            ## select the data after fly was exposed to the light\n",
    "            InLightDatainTheRange_P01 = df['InLight_HeadX|P01'][fly][int(firstLightContactIndex_P01):]\n",
    "            ## calculate PI score\n",
    "            numOfDataPoints_P01 = len(InLightDatainTheRange_P01)\n",
    "            numOfInLights_P01 = sum(InLightDatainTheRange_P01)\n",
    "            numOfInDarks_P01 = numOfDataPoints_P01 - numOfInLights_P01\n",
    "           \n",
    "            PI_P01 = float(numOfInLights_P01 - numOfInDarks_P01)/float(numOfDataPoints_P01)\n",
    "            PI_afterLightContact_P01.append(PI_P01)\n",
    "        \n",
    "        elif np.isnan(firstLightContactIndex_P01):\n",
    "            PI_afterLightContact_P01.append(np.nan)\n",
    "        \n",
    "        else:\n",
    "            None\n",
    "        \n",
    "        ## same as the first half of the exp: P01\n",
    "        if not np.isnan(firstLightContactIndex_P10):\n",
    "            \n",
    "            InLightDatainTheRange_P10 = df['InLight_HeadX|P10'][fly][int(firstLightContactIndex_P10):]\n",
    "            numOfDataPoints_P10 = len(InLightDatainTheRange_P10)\n",
    "            numOfInLights_P10 = sum(InLightDatainTheRange_P10)\n",
    "            numOfInDarks_P10 = numOfDataPoints_P10 - numOfInLights_P10\n",
    "            \n",
    "            PI_P10 = float(numOfInLights_P10 - numOfInDarks_P10)/float(numOfDataPoints_P10)\n",
    "            PI_afterLightContact_P10.append(PI_P10)\n",
    "        \n",
    "        elif np.isnan(firstLightContactIndex_P10):\n",
    "            PI_afterLightContact_P10.append(np.nan)\n",
    "        \n",
    "        else:\n",
    "            None\n",
    "        \n",
    "        ## add the Preference Index pattern01 and pattern10 to the df\n",
    "    df = df.assign(TSALE_P01 = pd.Series(PI_afterLightContact_P01, index=df.index),\n",
    "                   TSALE_P10 = pd.Series(PI_afterLightContact_P10, index=df.index))\n",
    "    \n",
    "    df = df.assign(TSALE_Mean = pd.Series(df[['TSALE_P01','TSALE_P10']].mean(axis=1), index=df.index))\n",
    "    \n",
    "    droppedNans = MeanPreferenceIndexNoNANs(df)\n",
    "    \n",
    "    if dropNans == True:\n",
    "        plotTheMetric(droppedNans,'TSALE',rootDir,combineControls,dropNans)\n",
    "        \n",
    "        return droppedNans\n",
    "    else:\n",
    "        plotTheMetric(df,'TSALE',rootDir,combineControls,dropNans)\n",
    "    \n",
    "        return df\n",
    "\n",
    "## Nans in the PreferenceIndex_P01 (and P10) columns are treated as not existing in the plotting;\n",
    "## therefore, when I am getting the mean of the two columns, I can't treat them as zeroes. \n",
    "## This function, first removes all the rows where either PreferenceIndex_P01 OR PreferenceIndex_P10 is Nan,\n",
    "## then calculates a PreferenceIndex_Mean column to the df.\n",
    "def MeanPreferenceIndexNoNANs(df):\n",
    "    \n",
    "    droppedNans = df.dropna(subset = ['TSALE_P10','TSALE_P01'])\n",
    "    droppedNans = droppedNans.assign(TSALE_Mean_noNan = pd.Series(droppedNans[['TSALE_P01','TSALE_P10']].mean(axis=1), index = droppedNans.index))\n",
    "    droppedNans = droppedNans.reset_index(drop=True)\n",
    "    \n",
    "    return droppedNans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: weighted-TSALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_TSALE(dff, rootDir,combineControls=False, dropNans=False):\n",
    "    \n",
    "    df = TSALE(dff, rootDir, dropNans, combineControls)\n",
    "    ## empty lists to store the weights for both epochs\n",
    "    weights_P01 = []\n",
    "    weights_P10 = []\n",
    "    numofflies = df.shape[0]\n",
    "    \n",
    "    ## calculate weights per fly\n",
    "    for i in range(numofflies):\n",
    "        numofFrames_P01 = len(df['InLight_HeadX|P01'][i])\n",
    "        firstContact_P01 = df['First light contact index in P01'][i]\n",
    "\n",
    "        if not np.isnan(firstContact_P01):\n",
    "            ## weight is calculated as: remaining time after the discovery / whole epoch\n",
    "            w_P01 = (numofFrames_P01-firstContact_P01)/float(numofFrames_P01)\n",
    "            weights_P01.append(w_P01)\n",
    "        else:\n",
    "            weights_P01.append(np.nan) \n",
    "\n",
    "        numofFrames_P10 = len(df['InLight_HeadX|P10'][i])\n",
    "        firstContact_P10 = df['First light contact index in P10'][i]\n",
    "\n",
    "        if not np.isnan(firstContact_P10):\n",
    "            ## weight is remaining time after the discovery / whole epoch\n",
    "            w_P10 = (numofFrames_P10-firstContact_P10)/float(numofFrames_P10)\n",
    "            weights_P10.append(w_P10)\n",
    "        else:\n",
    "            weights_P10.append(np.nan) \n",
    "\n",
    "    df = df.assign(weights_P01 = pd.Series(weights_P01, index=df.index),\n",
    "                   weights_P10 = pd.Series(weights_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(weighted_TSALE_P01 = pd.Series(df['weights_P01'] * df['TSALE_P01'], index=df.index),\n",
    "                   weighted_TSALE_P10 = pd.Series(df['weights_P10'] * df['TSALE_P10'], index=df.index))\n",
    "\n",
    "    df = df.assign(weighted_TSALE_Mean = pd.Series(df[['weighted_TSALE_P01','weighted_TSALE_P10']].mean(axis=1), index=df.index))\n",
    "    \n",
    "    plotTheMetric(df,'weighted_TSALE',rootDir,combineControls,dropNans)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: Light attraction index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function 1: Detect choice zone entrance/exits indices, store them in the df\n",
    "## Pass the df to these functions:\n",
    "    ## Function 2: Sort and Plot the tracts as in Wilson paper _ this only needs the entrance indices\n",
    "    ## Function 2.5: To plot the mean trajactories as in the Wilson paper, need an alignment function. Choice zone borders vary.\n",
    "    ## Function 3: Calculate Attraction Index from the exits _ this needs the exit indice, as well as coordination to decide \n",
    "    ## whether traversel or reversal.\n",
    "\n",
    "    ###!!! Fix HeadX to smoothed headX\n",
    "def DetectEntraceandExitIndicesToTheChoiceZone(df, choiceZoneWidth_mm = 10, thresholdToExcludeCursorJumps_pix = 20):\n",
    "\n",
    "    ## Lists to store the entrance and corresponding exits info per fly for P01 and P10\n",
    "    FromTheWindPortEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = []\n",
    "    FromTheClosedEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = []\n",
    "\n",
    "    FromTheWindPortEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = []\n",
    "    FromTheClosedEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = []\n",
    "    \n",
    "    ## Lists to stores choice zone borders per fly\n",
    "    ChoiceZoneBordersPerFly_P01 = []\n",
    "    ChoiceZoneBordersPerFly_P10 = []\n",
    "    \n",
    "    numberOfFlies = df.shape[0]\n",
    "\n",
    "    ## get the mm to pix coefficient\n",
    "    mmPerPix = df['mmPerPix'][0]\n",
    "\n",
    "    ## convert the zone width from mm to pix\n",
    "    choiceZoneWidth_pix = choiceZoneWidth_mm/mmPerPix\n",
    "\n",
    "    for fly in range(0,numberOfFlies):\n",
    "\n",
    "        ## one fly can have multiple decisions; I will keep seperate lists per fly\n",
    "        flyDecisionList_theWindPortEnd_P01 = []\n",
    "        flyDecisionList_theClosedEnd_P01 = []\n",
    "\n",
    "        flyDecisionList_theWindPortEnd_P10 = []\n",
    "        flyDecisionList_theClosedEnd_P10 = []\n",
    "\n",
    "        ## get border coordinates for the two light events per fly\n",
    "        border_P01 = df.iloc[fly]['Border|P01']\n",
    "        border_P10 = df.iloc[fly]['Border|P10'] \n",
    "\n",
    "        ## identify the choice zone lef-right borders per chamber, since borders change across chambers, even P01 vs P10 \n",
    "        choiceZoneBorders_P01 = [border_P01-choiceZoneWidth_pix/2, border_P01+choiceZoneWidth_pix/2]\n",
    "        choiceZoneBorders_P10 = [border_P10-choiceZoneWidth_pix/2, border_P10+choiceZoneWidth_pix/2]\n",
    "        \n",
    "        ## store the border info to be attached to the df\n",
    "        ChoiceZoneBordersPerFly_P01.append(choiceZoneBorders_P01)\n",
    "        ChoiceZoneBordersPerFly_P10.append(choiceZoneBorders_P10)\n",
    "        ## NTS: In Adam's paper, only when flies enter and exit counted as a decision.\n",
    "\n",
    "        ## get the indices where P01 and P10 were taking place      \n",
    "        P01_startIndex, P01_endIndex = df.iloc[fly]['LightON index|P01']\n",
    "        P10_startIndex, P10_endIndex = df.iloc[fly]['LightON index|P10']\n",
    "\n",
    "        ## get head X coordinates while the light was ON, P01 and P10\n",
    "        headXcoordIn_P01 = df.iloc[fly]['HeadX(pix)_smoothed'][P01_startIndex:P01_endIndex]\n",
    "        headXcoordIn_P10 = df.iloc[fly]['HeadX(pix)_smoothed'][P10_startIndex:P10_endIndex]\n",
    "\n",
    "        ## go thru the head X coordinates during the P01 event to find entrances and related exits(if any)\n",
    "        for i in range(len(headXcoordIn_P01)-1): \n",
    "            \n",
    "            ## if entering to the zone from the wind port end\n",
    "            if (headXcoordIn_P01[i] < choiceZoneBorders_P01[0]) & ((headXcoordIn_P01[i+1] > choiceZoneBorders_P01[0]) & (headXcoordIn_P01[i+1] < choiceZoneBorders_P01[1])):\n",
    "               \n",
    "                ## store the entrance info [entrance index, entrance coor]\n",
    "                temp = [P01_startIndex+i+1, headXcoordIn_P01[i+1]]\n",
    "\n",
    "                ## now detect the exit of this entrance\n",
    "                for j in range(len(headXcoordIn_P01[i:])-1):\n",
    "\n",
    "                    if (headXcoordIn_P01[i:][j+1] < choiceZoneBorders_P01[0]) | (headXcoordIn_P01[i:][j+1] > choiceZoneBorders_P01[1]):\n",
    "\n",
    "                        ## attach the exit to the temp list [entrance index, entrance coor, exit index, exit coor]\n",
    "                        temp.append(P01_startIndex+i+j+1)\n",
    "                        temp.append(headXcoordIn_P01[i+j+1])\n",
    "                        break\n",
    "\n",
    "                flyDecisionList_theWindPortEnd_P01.append(temp)\n",
    "                \n",
    "            ## found an entrance from the closed end of the chamber\n",
    "            if (headXcoordIn_P01[i] > choiceZoneBorders_P01[1]) & ((headXcoordIn_P01[i+1] < choiceZoneBorders_P01[1]) & (headXcoordIn_P01[i+1] > choiceZoneBorders_P01[0])):\n",
    "\n",
    "                ## store the entrance info [entrance index, entrance coor]\n",
    "                temp = [P01_startIndex+i+1, headXcoordIn_P01[i+1]]\n",
    "\n",
    "                ## now detect the exit of this entrance, if any\n",
    "                for j in range(len(headXcoordIn_P01[i:])-1):\n",
    "\n",
    "                    if (headXcoordIn_P01[i:][j+1] < choiceZoneBorders_P01[0]) | (headXcoordIn_P01[i:][j+1] > choiceZoneBorders_P01[1]):\n",
    "\n",
    "                        ## attach the exit to the temp list [entrance index, entrance coor, exit index, exit coor]\n",
    "                        temp.append(P01_startIndex+i+j+1)\n",
    "                        temp.append(headXcoordIn_P01[i+j+1])\n",
    "                        break\n",
    "                        \n",
    "                ## add this decision to the list before searching for other decisions of the same fly \n",
    "                flyDecisionList_theClosedEnd_P01.append(temp)\n",
    "        \n",
    "        \n",
    "        ## go thru the head X coordinates during the P10 event to find entrances and related exits(if any)\n",
    "        for i in range(len(headXcoordIn_P10)-1): \n",
    "            \n",
    "            ## if entering to the zone from the wind port end\n",
    "            if (headXcoordIn_P10[i] < choiceZoneBorders_P10[0]) & ((headXcoordIn_P10[i+1] > choiceZoneBorders_P10[0]) & (headXcoordIn_P10[i+1] < choiceZoneBorders_P10[1])):\n",
    "                \n",
    "                ## store the entrance info [entrance index, entrance coor]\n",
    "                temp = [P10_startIndex+i+1, headXcoordIn_P10[i+1]]\n",
    "                \n",
    "                ## now detect the exit of this entrance\n",
    "                for j in range(len(headXcoordIn_P10[i:])-1):\n",
    "\n",
    "                    if (headXcoordIn_P10[i:][j+1] < choiceZoneBorders_P10[0]) | (headXcoordIn_P10[i:][j+1] > choiceZoneBorders_P10[1]):\n",
    "\n",
    "                        ## attach the exit to the temp list [entrance index, entrance coor, exit index, exit coor]\n",
    "                        temp.append(P10_startIndex+i+j+1)\n",
    "                        temp.append(headXcoordIn_P10[i+j+1])\n",
    "                        break\n",
    "\n",
    "                flyDecisionList_theWindPortEnd_P10.append(temp)\n",
    "                \n",
    "            ## found an entrance from the closed end of the chamber\n",
    "            if (headXcoordIn_P10[i] > choiceZoneBorders_P10[1]) & ((headXcoordIn_P10[i+1] < choiceZoneBorders_P10[1]) & (headXcoordIn_P10[i+1] > choiceZoneBorders_P10[0])):\n",
    "\n",
    "                ## store the entrance info [entrance index, entrance coor]\n",
    "                temp = [P10_startIndex+i+1, headXcoordIn_P10[i+1]]\n",
    "\n",
    "                ## now detect the exit of this entrance, if any\n",
    "                for j in range(len(headXcoordIn_P10[i:])-1):\n",
    "\n",
    "                    if (headXcoordIn_P10[i:][j+1] < choiceZoneBorders_P10[0]) | (headXcoordIn_P10[i:][j+1] > choiceZoneBorders_P10[1]):\n",
    "\n",
    "                        ## attach the exit to the temp lis, [entrance index, entrance coor, exit index, exit coor]\n",
    "                        temp.append(P10_startIndex+i+j+1)\n",
    "                        temp.append(headXcoordIn_P10[i+j+1])\n",
    "                        break\n",
    "                        \n",
    "                ## add this decision to the list before searching for other decisions of the same fly \n",
    "                flyDecisionList_theClosedEnd_P10.append(temp)\n",
    "\n",
    "        FromTheWindPortEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX.append(flyDecisionList_theWindPortEnd_P01)\n",
    "        FromTheClosedEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX.append(flyDecisionList_theClosedEnd_P01)\n",
    "\n",
    "        FromTheWindPortEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX.append(flyDecisionList_theWindPortEnd_P10)\n",
    "        FromTheClosedEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX.append(flyDecisionList_theClosedEnd_P10)\n",
    "    \n",
    "    df = df.assign(ChoiceZoneBordersperFly_P01 = pd.Series(ChoiceZoneBordersPerFly_P01, index=df.index),\n",
    "                   ChoiceZoneBordersperFly_P10 = pd.Series(ChoiceZoneBordersPerFly_P10, index=df.index),\n",
    "                   FromTheWindPortEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = pd.Series(FromTheWindPortEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX, index=df.index),\n",
    "                   FromTheClosedEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = pd.Series(FromTheClosedEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX, index=df.index),\n",
    "                   FromTheWindPortEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = pd.Series(FromTheWindPortEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX, index=df.index),\n",
    "                   FromTheClosedEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = pd.Series(FromTheClosedEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX, index=df.index))\n",
    "    return df\n",
    "\n",
    "def LAI(df, rootDir, combineControls=False, dropNans=False):\n",
    " \n",
    "    ## Caution: when you are calculating the LAI_Mean, getting the avarage of P01 and P10 may yield different results than\n",
    "    ## counting the votes for the two epochs.\n",
    "    ## P01 most probably will be excluded due to the conflicting of interpretations when the wind applied.\n",
    "    ## So, don't worry too much about the mean LAI.\n",
    "    ## LAI does not need to be calculated seperately for down and upwind cases. Combine them together.\n",
    "    ## The downwind/upwind will be nice to see in the path-analysis, and number of border crossings.\n",
    "    df = DetectEntraceandExitIndicesToTheChoiceZone(df)\n",
    "    \n",
    "    LightAttractionIndex_P01 = []\n",
    "    LightAttractionIndex_P10 = []\n",
    "\n",
    "    # go through all the flies\n",
    "    for fly in range(len(df)):\n",
    "\n",
    "        entrance_exit_log_P01 = []\n",
    "        entrance_exit_log_P10 = []\n",
    "\n",
    "        number_of_light_votes_P01 = 0\n",
    "        number_of_dark_votes_P01 = 0\n",
    "\n",
    "        number_of_light_votes_P10 = 0\n",
    "        number_of_dark_votes_P10 = 0\n",
    "        ## combine the choice events for P01 and P10, regardless to which part of the chamber flies entered to the zone\n",
    "        entrance_exit_log_P01.extend(df['FromTheClosedEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "        entrance_exit_log_P01.extend(df['FromTheWindPortEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "\n",
    "        entrance_exit_log_P10.extend(df['FromTheClosedEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "        entrance_exit_log_P10.extend(df['FromTheWindPortEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "\n",
    "        ## get the choice zone borders per fly to detect whether exit was to light or dark side\n",
    "        border_P01 = df['Border|P01'][fly]\n",
    "        border_P10 = df['Border|P10'][fly]\n",
    "        ## go thru the entrances per fly and find out where the exits were made to\n",
    "        ## note that the light and dark sides are different sides of the border in each epoch\n",
    "        ## for P01\n",
    "        if entrance_exit_log_P01:\n",
    "            for log in entrance_exit_log_P01:\n",
    "                if len(log) == 4:\n",
    "                    exit_headX = log[3]\n",
    "                    \n",
    "                    ## NTS: using border line, instead of the choice zone borders, to compare the exit headX. Otherwise it\n",
    "                    ## fucks up.\n",
    "                    ##exit to the light side\n",
    "                    if exit_headX > border_P01:\n",
    "                        number_of_light_votes_P01 = number_of_light_votes_P01 + 1\n",
    "\n",
    "                    ##exit to the dark side    \n",
    "                    elif exit_headX < border_P01:\n",
    "                        number_of_dark_votes_P01 =  number_of_dark_votes_P01 + 1\n",
    "            \n",
    "            if (number_of_light_votes_P01 + number_of_dark_votes_P01) != 0:\n",
    "                LAI_P01 = (float(number_of_light_votes_P01) - float(number_of_dark_votes_P01))/(float(number_of_light_votes_P01) + float(number_of_dark_votes_P01))\n",
    "                LightAttractionIndex_P01.append(LAI_P01)\n",
    "            else:\n",
    "                LightAttractionIndex_P01.append(np.nan)\n",
    "        else:\n",
    "            LightAttractionIndex_P01.append(np.nan)\n",
    "            \n",
    "        ## for P10\n",
    "        if entrance_exit_log_P10:\n",
    "            for log in entrance_exit_log_P10:\n",
    "                if len(log) == 4:\n",
    "                    exit_headX = log[3]\n",
    "\n",
    "                    ##exit to the dark side\n",
    "                    if exit_headX > border_P10:\n",
    "                        number_of_dark_votes_P10 =  number_of_dark_votes_P10 + 1\n",
    "\n",
    "                    ##exit to the light side    \n",
    "                    elif exit_headX < border_P10:\n",
    "                        number_of_light_votes_P10 = number_of_light_votes_P10 + 1\n",
    "            if (number_of_light_votes_P10 + number_of_dark_votes_P10) != 0:\n",
    "                LAI_P10 = (float(number_of_light_votes_P10) - float(number_of_dark_votes_P10))/(float(number_of_light_votes_P10) + float(number_of_dark_votes_P10))\n",
    "                LightAttractionIndex_P10.append(LAI_P10)\n",
    "            else:\n",
    "                LightAttractionIndex_P10.append(np.nan)\n",
    "        else:\n",
    "            LightAttractionIndex_P10.append(np.nan) \n",
    "\n",
    "    df = df.assign(LAI_P01 = pd.Series(LightAttractionIndex_P01, index=df.index),\n",
    "                   LAI_P10 = pd.Series(LightAttractionIndex_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(LAI_Mean = pd.Series(df[['LAI_P01','LAI_P10']].mean(axis=1), index=df.index))\n",
    "    plotTheMetric(df,'LAI',rootDir,combineControls,dropNans)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrix: Reversal PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RPI(df, rootDir, combineControls=False, dropNans=False):\n",
    " \n",
    "    df = DetectEntraceandExitIndicesToTheChoiceZone(df)\n",
    "    \n",
    "    ReversalPI_P01 = []\n",
    "    ReversalPI_P10 = []\n",
    "    \n",
    "    # go through all the flies\n",
    "    for fly in range(len(df)):\n",
    "\n",
    "        entrance_exit_log_P01 = []\n",
    "        entrance_exit_log_P10 = []\n",
    "\n",
    "        number_of_light_reversals_P01 = 0\n",
    "        number_of_dark_reversals_P01 = 0\n",
    "\n",
    "        number_of_light_reversals_P10 = 0\n",
    "        number_of_dark_reversals_P10 = 0\n",
    "        \n",
    "        ## Use both the wind port and closed end entrances\n",
    "        entrance_exit_log_P01.extend(df['FromTheClosedEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "        entrance_exit_log_P01.extend(df['FromTheWindPortEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "\n",
    "        entrance_exit_log_P10.extend(df['FromTheClosedEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "        entrance_exit_log_P10.extend(df['FromTheWindPortEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "\n",
    "        ## get the border lines per fly to detect whether exit was to light or dark side\n",
    "        border_P01 = df['Border|P01'][fly]\n",
    "        border_P10 = df['Border|P10'][fly]\n",
    "        \n",
    "        ## go thru the entrances per fly and find out where the exits were made to\n",
    "        ## note that the light and dark sides are different sides of the border in each epoch\n",
    "        ## for P01\n",
    "        if entrance_exit_log_P01:\n",
    "            for log in entrance_exit_log_P01:\n",
    "                if len(log) == 4:\n",
    "                    enter_headX = log[1]\n",
    "                    exit_headX = log[3]\n",
    "                    \n",
    "                    ##came from to the dark side, returned to the dark side\n",
    "                    if (enter_headX < border_P01) & (exit_headX < border_P01):\n",
    "                        number_of_dark_reversals_P01 = number_of_dark_reversals_P01 + 1\n",
    "\n",
    "                    ##came from the lit side, returned to the lit side   \n",
    "                    elif (enter_headX > border_P01) & (exit_headX > border_P01):\n",
    "                        number_of_light_reversals_P01 =  number_of_light_reversals_P01 + 1\n",
    "                        \n",
    "            if (number_of_dark_reversals_P01 + number_of_light_reversals_P01) != 0:\n",
    "                RPI_P01 = (float(number_of_light_reversals_P01) - float(number_of_dark_reversals_P01))/(float(number_of_light_reversals_P01) + float(number_of_dark_reversals_P01))\n",
    "                ReversalPI_P01.append(RPI_P01)\n",
    "                \n",
    "            else:\n",
    "                ReversalPI_P01.append(np.nan)\n",
    "        else:\n",
    "            ReversalPI_P01.append(np.nan)\n",
    "            \n",
    "        ## for P10\n",
    "        if entrance_exit_log_P10:\n",
    "            for log in entrance_exit_log_P10:\n",
    "                if len(log) == 4:\n",
    "                    enter_headX = log[1]\n",
    "                    exit_headX = log[3]\n",
    "\n",
    "                    ##came from light, returned to the lit side\n",
    "                    if (enter_headX < border_P10) & (exit_headX < border_P10):\n",
    "                        number_of_light_reversals_P10 =  number_of_light_reversals_P10 + 1\n",
    "\n",
    "                    ##came from the dark half, returned to the dark half   \n",
    "                    elif (enter_headX > border_P10) & (exit_headX > border_P10):\n",
    "                        number_of_dark_reversals_P10 = number_of_dark_reversals_P10 + 1\n",
    "                        \n",
    "            if (number_of_dark_reversals_P10 + number_of_light_reversals_P10) != 0:\n",
    "                RPI_P10 = (float(number_of_light_reversals_P10) - float(number_of_dark_reversals_P10))/(float(number_of_dark_reversals_P10) + float(number_of_light_reversals_P10))\n",
    "                ReversalPI_P10.append(RPI_P10)\n",
    "            else:\n",
    "                ReversalPI_P10.append(np.nan)\n",
    "        else:\n",
    "            ReversalPI_P10.append(np.nan) \n",
    "\n",
    "    df = df.assign(RPI_P01 = pd.Series(ReversalPI_P01, index=df.index),\n",
    "                   RPI_P10 = pd.Series(ReversalPI_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(RPI_Mean = pd.Series(df[['RPI_P01','RPI_P10']].mean(axis=1), index=df.index))\n",
    "    \n",
    "    plotTheMetric(df,'RPI',rootDir,combineControls,dropNans)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: Number of Border Crossings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### NTS: fix this to SMOOTHED HEAD X!!\n",
    "def NoBC(df, rootDir, combineControls=False, dropNans=False):\n",
    "    \n",
    "    ## lists to keep the metric for each fly\n",
    "    list_of_number_of_border_crossings_P01 = []\n",
    "    list_of_number_of_border_crossings_P10 = []\n",
    "\n",
    "    for fly in range(len(df)):\n",
    "\n",
    "        ## get the P01 and P10 epoch indices\n",
    "        start_of_P01 = df['LightON index|P01'][fly][0]\n",
    "        end_of_P01 = df['LightON index|P01'][fly][1]\n",
    "\n",
    "        start_of_P10 = df['LightON index|P10'][fly][0]\n",
    "        end_of_P10 = df['LightON index|P10'][fly][1]\n",
    "\n",
    "        ## get the head X positions during the epochs\n",
    "        headX_during_P01 = df['HeadX(pix)_smoothed'][fly][start_of_P01:end_of_P01]\n",
    "        headX_during_P10 = df['HeadX(pix)_smoothed'][fly][start_of_P10:end_of_P10]\n",
    "\n",
    "        ## get the border corrdinates\n",
    "        border_P01 = df['Border|P01'][fly]\n",
    "        border_P10 = df['Border|P10'][fly]\n",
    "\n",
    "        ## values to keep the crossings for each fly\n",
    "        number_of_border_crossings_P01 = 0\n",
    "        number_of_border_crossings_P10 = 0\n",
    "\n",
    "        ## go thru the headX coords and detect border crossings\n",
    "        ## for P01 epoch\n",
    "        for i in range(len(headX_during_P01)-1):\n",
    "            current_coor = headX_during_P01[i]\n",
    "            next_coor = headX_during_P01[i+1]\n",
    "\n",
    "            if (current_coor > border_P01) & (next_coor < border_P01):\n",
    "                number_of_border_crossings_P01 = number_of_border_crossings_P01 + 1\n",
    "            elif (current_coor < border_P01) & (next_coor > border_P01):\n",
    "                number_of_border_crossings_P01 = number_of_border_crossings_P01 + 1\n",
    "        list_of_number_of_border_crossings_P01.append(number_of_border_crossings_P01)\n",
    "\n",
    "        ## go thru the headX coords and detect border crossings\n",
    "        ## for P10 epoch\n",
    "        for i in range(len(headX_during_P10)-1):\n",
    "            current_coor = headX_during_P10[i]\n",
    "            next_coor = headX_during_P10[i+1]\n",
    "\n",
    "            if (current_coor > border_P10) & (next_coor < border_P10):\n",
    "                number_of_border_crossings_P10 = number_of_border_crossings_P10 + 1\n",
    "                \n",
    "            elif (current_coor < border_P10) & (next_coor > border_P10):\n",
    "                number_of_border_crossings_P10 = number_of_border_crossings_P10 + 1\n",
    "\n",
    "        list_of_number_of_border_crossings_P10.append(number_of_border_crossings_P10)\n",
    "    \n",
    "    df = df.assign(NoBC_P01 = pd.Series(list_of_number_of_border_crossings_P01, index=df.index),\n",
    "                   NoBC_P10 = pd.Series(list_of_number_of_border_crossings_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(NoBC_Mean = pd.Series(df[['NoBC_P01','NoBC_P10']].mean(axis=1), index=df.index))\n",
    "    plotTheMetric(df,'NoBC',rootDir,combineControls,dropNans)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: Speed ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### NTS: convert HeadX to SMOOTHED HEADX\n",
    "\n",
    "## 1. detect the chunks of headX that were in the epoch regions for before_the_light_P01, during_the_light_P01..\n",
    "## 2. calculate total distance travelled and total number of frames\n",
    "## 3. convert them into mm and sec\n",
    "## 4. calculate the ratio\n",
    "\n",
    "def calculateSpeed(data, fps, mmPerPixel):\n",
    "    \n",
    "    number_of_frames = 0\n",
    "    total_distance_pixel = 0\n",
    "    \n",
    "    ## Go thru the chunks of contuniued headX coordinates\n",
    "    for sublist in data:\n",
    "        for distance in sublist:\n",
    "            total_distance_pixel = total_distance_pixel + distance\n",
    "            number_of_frames = number_of_frames + 1\n",
    "    \n",
    "    if (number_of_frames != 0) & (total_distance_pixel != 0):\n",
    "        total_time_sec = float(number_of_frames) / float(fps)\n",
    "        total_distance_mm = total_distance_pixel * mmPerPixel\n",
    "\n",
    "        speed_pix_per_frame = float(total_distance_pixel)/float(number_of_frames)\n",
    "        speed_mm_per_sec = float(total_distance_mm)/float(total_time_sec)\n",
    "\n",
    "    else:\n",
    "        speed_pix_per_frame = np.nan\n",
    "        speed_mm_per_sec = np.nan\n",
    "        \n",
    "    return speed_mm_per_sec\n",
    "\n",
    "def Log2SpeedRatio(df ,rootDir, combineControls=False, dropNans=False):\n",
    "    list_of_log2_speed_ratio_P01 = []\n",
    "    list_of_log2_speed_ratio_P10 = []\n",
    "\n",
    "    for fly in range(len(df)):\n",
    "    \n",
    "        ## get the light ON indices to detect before and during light episodes in an experiment\n",
    "        lightON_P01 = df['LightON index|P01'][fly]\n",
    "        lightON_P10 = df['LightON index|P10'][fly] \n",
    "\n",
    "        ## get the borders\n",
    "        border_P01 = df['Border|P01'][fly]\n",
    "        border_P10 = df['Border|P01'][fly]\n",
    "\n",
    "        ## get fps and mmPerPixel for speed calculation\n",
    "        fps = df['fps'][fly]\n",
    "        mmPerPixel = df['mmPerPix'][fly]\n",
    "        ## get the fly's headX for the entire exp\n",
    "        fly_headX_coords = df['HeadX(pix)_smoothed'][fly]\n",
    "\n",
    "        ##  chop up the headX into the episodes\n",
    "        before_the_light_P01_headX = fly_headX_coords[:lightON_P01[0]]\n",
    "        during_the_light_P01_headX = fly_headX_coords[lightON_P01[0]:lightON_P01[1]]\n",
    "\n",
    "        before_the_light_P10_headX = fly_headX_coords[lightON_P01[1]:lightON_P10[0]]\n",
    "        during_the_light_P10_headX = fly_headX_coords[lightON_P10[0]:lightON_P10[1]]\n",
    "\n",
    "        ## lists to keep the chunks (lists) of headX there were in the region that the light was going to be turned ON\n",
    "        before_the_light_P01_headX_in_the_region = []\n",
    "        during_the_light_P01_headX_in_the_region = []\n",
    "\n",
    "        before_the_light_P10_headX_in_the_region = []\n",
    "        during_the_light_P10_headX_in_the_region = []\n",
    "\n",
    "        ## keep the indices of headX where they are in the region of interest\n",
    "        ## for P01\n",
    "        before_the_light_P01_headX_temp = []\n",
    "        for i in range(len(before_the_light_P01_headX)):\n",
    "            if before_the_light_P01_headX[i] > border_P01:\n",
    "                before_the_light_P01_headX_temp.append(i)\n",
    "\n",
    "        during_the_light_P01_headX_temp = []\n",
    "        for i in range(len(during_the_light_P01_headX)):\n",
    "            if during_the_light_P01_headX[i] > border_P01:\n",
    "                during_the_light_P01_headX_temp.append(i)\n",
    "\n",
    "        ## for P10\n",
    "        before_the_light_P10_headX_temp = []\n",
    "        for i in range(len(before_the_light_P10_headX)):\n",
    "            if before_the_light_P10_headX[i] < border_P10:\n",
    "                before_the_light_P10_headX_temp.append(i)\n",
    "\n",
    "        during_the_light_P10_headX_temp = []\n",
    "        for i in range(len(during_the_light_P10_headX)):\n",
    "            if during_the_light_P10_headX[i] < border_P10:\n",
    "                during_the_light_P10_headX_temp.append(i)\n",
    "\n",
    "        ## chop up the indices' lists and find consecutives\n",
    "        for k, g in groupby(enumerate(before_the_light_P01_headX_temp), lambda (i,x):i-x):\n",
    "            sublist = map(itemgetter(1), g)\n",
    "            if len(sublist) > 1:\n",
    "                before_the_light_P01_headX_in_the_region.append(sublist)\n",
    "\n",
    "        for k, g in groupby(enumerate(during_the_light_P01_headX_temp), lambda (i,x):i-x):\n",
    "            sublist = map(itemgetter(1), g)\n",
    "            if len(sublist) > 1:\n",
    "                during_the_light_P01_headX_in_the_region.append(sublist)\n",
    "\n",
    "        for k, g in groupby(enumerate(before_the_light_P10_headX_temp), lambda (i,x):i-x):\n",
    "            sublist = map(itemgetter(1), g)\n",
    "            if len(sublist) > 1:\n",
    "                before_the_light_P10_headX_in_the_region.append(sublist)\n",
    "\n",
    "        for k, g in groupby(enumerate(during_the_light_P10_headX_temp), lambda (i,x):i-x):\n",
    "            sublist = map(itemgetter(1), g)\n",
    "            if len(sublist) > 1:\n",
    "                during_the_light_P10_headX_in_the_region.append(sublist)\n",
    "\n",
    "        ## By using the index lists, create distance travelled lists of lists.\n",
    "        ## For P01\n",
    "        before_the_light_P01_headX_in_the_region_distance_travelled = []\n",
    "\n",
    "        for l in before_the_light_P01_headX_in_the_region:\n",
    "            start_idx = l[0]\n",
    "            end_idx = l[-1]\n",
    "            temp = []\n",
    "\n",
    "            for i in range(start_idx,end_idx):\n",
    "                diff = abs(before_the_light_P01_headX[i+1] - before_the_light_P01_headX[i])\n",
    "                temp.append(diff)\n",
    "            before_the_light_P01_headX_in_the_region_distance_travelled.append(temp)\n",
    "\n",
    "        during_the_light_P01_headX_in_the_region_distance_travelled = []\n",
    "\n",
    "        for l in during_the_light_P01_headX_in_the_region:\n",
    "            start_idx = l[0]\n",
    "            end_idx = l[-1]\n",
    "            temp = []\n",
    "\n",
    "            for i in range(start_idx,end_idx):\n",
    "                diff = abs(during_the_light_P01_headX[i+1] - during_the_light_P01_headX[i])\n",
    "                temp.append(diff)\n",
    "            during_the_light_P01_headX_in_the_region_distance_travelled.append(temp)\n",
    "\n",
    "        ## for P10\n",
    "        before_the_light_P10_headX_in_the_region_distance_travelled = []\n",
    "\n",
    "        for l in before_the_light_P10_headX_in_the_region:\n",
    "            start_idx = l[0]\n",
    "            end_idx = l[-1]\n",
    "            temp = []\n",
    "\n",
    "            for i in range(start_idx,end_idx):\n",
    "                diff = abs(before_the_light_P10_headX[i+1] - before_the_light_P10_headX[i])\n",
    "                temp.append(diff)\n",
    "            before_the_light_P10_headX_in_the_region_distance_travelled.append(temp)\n",
    "\n",
    "        during_the_light_P10_headX_in_the_region_distance_travelled = []\n",
    "\n",
    "        for l in during_the_light_P10_headX_in_the_region:\n",
    "            start_idx = l[0]\n",
    "            end_idx = l[-1]\n",
    "            temp = []\n",
    "\n",
    "            for i in range(start_idx,end_idx):\n",
    "                diff = abs(during_the_light_P10_headX[i+1] - during_the_light_P10_headX[i])\n",
    "                temp.append(diff)\n",
    "            during_the_light_P10_headX_in_the_region_distance_travelled.append(temp)\n",
    "\n",
    "        ## Send the distance travelled lists to the calculateSpeed function to get an average speed (mm/sec)    \n",
    "        speed_before_the_light_P01_headX_in_the_region = calculateSpeed(before_the_light_P01_headX_in_the_region_distance_travelled, fps, mmPerPixel)\n",
    "        speed_during_the_light_P01_headX_in_the_region = calculateSpeed(during_the_light_P01_headX_in_the_region_distance_travelled, fps, mmPerPixel)\n",
    "\n",
    "        speed_before_the_light_P10_headX_in_the_region = calculateSpeed(before_the_light_P10_headX_in_the_region_distance_travelled, fps, mmPerPixel)\n",
    "        speed_during_the_light_P10_headX_in_the_region = calculateSpeed(during_the_light_P10_headX_in_the_region_distance_travelled, fps, mmPerPixel)\n",
    "\n",
    "        ## Calculate the speed ratios for P01 and P10\n",
    "        speed_ratio_P01 = speed_during_the_light_P01_headX_in_the_region / speed_before_the_light_P01_headX_in_the_region\n",
    "        speed_ratio_P10 = speed_during_the_light_P10_headX_in_the_region / speed_before_the_light_P10_headX_in_the_region\n",
    "\n",
    "        ## Get and Store the log2 of the ratios\n",
    "        log2_speed_ratio_P01 = math.log(speed_ratio_P01, 2.0)\n",
    "        log2_speed_ratio_P10 = math.log(speed_ratio_P10, 2.0)\n",
    "\n",
    "        list_of_log2_speed_ratio_P01.append(log2_speed_ratio_P01)\n",
    "        list_of_log2_speed_ratio_P10.append(log2_speed_ratio_P10)\n",
    "\n",
    "\n",
    "    df = df.assign(Log2SpeedRatio_P01 = pd.Series(list_of_log2_speed_ratio_P01, index=df.index),\n",
    "                   Log2SpeedRatio_P10 = pd.Series(list_of_log2_speed_ratio_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(Log2SpeedRatio_Mean = pd.Series(df[['Log2SpeedRatio_P01','Log2SpeedRatio_P10']].mean(axis=1), index=df.index))\n",
    "    plotTheMetric(df,'Log2SpeedRatio',rootDir,combineControls,dropNans)\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: Delta Time Spent Before and During Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculatePercentageTimeSpent(data, total_epoch_time):\n",
    "    \n",
    "    percentageTimeSpent = float(len(data)) / float(total_epoch_time) * 100\n",
    "    \n",
    "    return percentageTimeSpent\n",
    "\n",
    "def DeltaPercentTimeSpent(df, rootDir, combineControls=False, dropNans=False):\n",
    "    list_of_delta_per_time_spent_P01 = []\n",
    "    list_of_delta_per_time_spent_P10 = []\n",
    "\n",
    "    for fly in range(len(df)):\n",
    "\n",
    "        ## get the light ON indices to detect before and during light episodes in an experiment\n",
    "        lightON_P01 = df['LightON index|P01'][fly]\n",
    "        lightON_P10 = df['LightON index|P10'][fly] \n",
    "\n",
    "        ## get the borders\n",
    "        border_P01 = df['Border|P01'][fly]\n",
    "        border_P10 = df['Border|P01'][fly]\n",
    "\n",
    "        ## get the fly's headX for the entire exp\n",
    "        fly_headX_coords = df['HeadX(pix)_smoothed'][fly]\n",
    "\n",
    "        ##  chop up the headX into the episodes\n",
    "        before_the_light_P01_headX = fly_headX_coords[:lightON_P01[0]]\n",
    "        during_the_light_P01_headX = fly_headX_coords[lightON_P01[0]:lightON_P01[1]]\n",
    "\n",
    "        before_the_light_P10_headX = fly_headX_coords[lightON_P01[1]:lightON_P10[0]]\n",
    "        during_the_light_P10_headX = fly_headX_coords[lightON_P10[0]:lightON_P10[1]]\n",
    "\n",
    "        ## lists to keep the chunks (lists) of headX there were in the region that the light was going to be turned ON\n",
    "        before_the_light_P01_headX_in_the_region = []\n",
    "        during_the_light_P01_headX_in_the_region = []\n",
    "\n",
    "        before_the_light_P10_headX_in_the_region = []\n",
    "        during_the_light_P10_headX_in_the_region = []\n",
    "\n",
    "        ## keep the indices of headX where they are in the region of interest\n",
    "        ## for P01\n",
    "        before_the_light_P01_headX_temp = []\n",
    "        for i in range(len(before_the_light_P01_headX)):\n",
    "            if before_the_light_P01_headX[i] > border_P01:\n",
    "                before_the_light_P01_headX_temp.append(i)\n",
    "\n",
    "        during_the_light_P01_headX_temp = []\n",
    "        for i in range(len(during_the_light_P01_headX)):\n",
    "            if during_the_light_P01_headX[i] > border_P01:\n",
    "                during_the_light_P01_headX_temp.append(i)\n",
    "\n",
    "        ## for P10\n",
    "        before_the_light_P10_headX_temp = []\n",
    "        for i in range(len(before_the_light_P10_headX)):\n",
    "            if before_the_light_P10_headX[i] < border_P10:\n",
    "                before_the_light_P10_headX_temp.append(i)\n",
    "\n",
    "        during_the_light_P10_headX_temp = []\n",
    "        for i in range(len(during_the_light_P10_headX)):\n",
    "            if during_the_light_P10_headX[i] < border_P10:\n",
    "                during_the_light_P10_headX_temp.append(i)\n",
    "\n",
    "        ## calculate the percentage of the time spent in the region of interest\n",
    "        before_the_light_P01_perTimeSpent = calculatePercentageTimeSpent(before_the_light_P01_headX_temp, len(before_the_light_P01_headX))\n",
    "        during_the_light_P01_perTimeSpent = calculatePercentageTimeSpent(during_the_light_P01_headX_temp, len(during_the_light_P01_headX))\n",
    "\n",
    "        before_the_light_P10_perTimeSpent = calculatePercentageTimeSpent(before_the_light_P10_headX_temp, len(before_the_light_P10_headX))\n",
    "        during_the_light_P10_perTimeSpent = calculatePercentageTimeSpent(during_the_light_P10_headX_temp, len(during_the_light_P10_headX))\n",
    "\n",
    "        ## get the difference between dark and light phases\n",
    "        deltaPerTimeSpent_P01 = during_the_light_P01_perTimeSpent - before_the_light_P01_perTimeSpent\n",
    "        deltaPerTimeSpent_P10 = during_the_light_P10_perTimeSpent - before_the_light_P10_perTimeSpent\n",
    "\n",
    "        list_of_delta_per_time_spent_P01.append(deltaPerTimeSpent_P01)\n",
    "        list_of_delta_per_time_spent_P10.append(deltaPerTimeSpent_P10)\n",
    "\n",
    "\n",
    "    df = df.assign(DeltaPercentTimeSpent_P01 = pd.Series(list_of_delta_per_time_spent_P01, index=df.index),\n",
    "                   DeltaPercentTimeSpent_P10 = pd.Series(list_of_delta_per_time_spent_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(DeltaPercentTimeSpent_Mean = pd.Series(df[['DeltaPercentTimeSpent_P01','DeltaPercentTimeSpent_P10']].mean(axis=1), index=df.index))\n",
    "    plotTheMetric(df,'DeltaPercentTimeSpent',rootDir,combineControls,dropNans)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: Speed crossing inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NTS: CHANGE to SMOOTHED HEADX\n",
    "def calculateAcuteSpeed(data, crossing_idx, fps, mmPerPix, length_sec=3):\n",
    "    sec_to_frames = length_sec * fps\n",
    "    crossing_phase = data[crossing_idx:crossing_idx+sec_to_frames]\n",
    "    \n",
    "    total_distance_pix = np.sum(np.absolute(np.diff(crossing_phase)))\n",
    "    total_distance_mm = total_distance_pix * mmPerPix\n",
    "\n",
    "    acute_speed_pix_per_frame = float(total_distance_pix)/float(sec_to_frames)\n",
    "    acute_speed_mm_per_sec = float(total_distance_mm)/float(length_sec)\n",
    "    \n",
    "    return acute_speed_mm_per_sec\n",
    "\n",
    "def SpeedCrossingInside(df, rootDir, combineControls=False, dropNans=False):\n",
    "    ## lists to keep the metric for each fly\n",
    "    averaged_list_of_acute_speed_crossing_inside_P01 = []\n",
    "    averaged_list_of_acute_speed_crossing_inside_P10 = []\n",
    "\n",
    "    for fly in range(len(df)):\n",
    "        ## lists to keep the metric for each fly\n",
    "        list_of_acute_speed_crossing_inside_P01 = []\n",
    "        list_of_acute_speed_crossing_inside_P10 = []\n",
    "\n",
    "        ## get the P01 and P10 epoch indices\n",
    "        start_of_P01 = df['LightON index|P01'][fly][0]\n",
    "        end_of_P01 = df['LightON index|P01'][fly][1]\n",
    "\n",
    "        start_of_P10 = df['LightON index|P10'][fly][0]\n",
    "        end_of_P10 = df['LightON index|P10'][fly][1]\n",
    "\n",
    "        ## get the head X positions during the epochs\n",
    "        headX_during_P01 = df['HeadX(pix)_smoothed'][fly][start_of_P01:end_of_P01]\n",
    "        headX_during_P10 = df['HeadX(pix)_smoothed'][fly][start_of_P10:end_of_P10]\n",
    "\n",
    "        ## get the border corrdinates\n",
    "        border_P01 = df['Border|P01'][fly]\n",
    "        border_P10 = df['Border|P10'][fly]\n",
    "\n",
    "        ## get the fps for acute speed calculations\n",
    "        fps = df['fps'][fly]\n",
    "        mmPerPix = df['mmPerPix'][fly]\n",
    "\n",
    "        ## go thru the headX coords and detect border crossings\n",
    "        ## every time detect a cross, send the index to the calculateAcuteSpeed function\n",
    "        ## for P01 epoch\n",
    "        for i in range(len(headX_during_P01)-1):\n",
    "            current_coor = headX_during_P01[i]\n",
    "            next_coor = headX_during_P01[i+1]\n",
    "\n",
    "            ## only when crossing inside            \n",
    "            if (current_coor < border_P01) & (next_coor > border_P01):\n",
    "                acute_speed_change_crossing_inside_P01 = calculateAcuteSpeed(headX_during_P01, crossing_idx = i, fps = fps, mmPerPix = mmPerPix, length_sec = 3)\n",
    "                list_of_acute_speed_crossing_inside_P01.append(acute_speed_change_crossing_inside_P01)\n",
    "\n",
    "                ## Since each fly can have multiple border crossings and hence acute speeds,I get the average per fly.\n",
    "        if list_of_acute_speed_crossing_inside_P01 > 0:\n",
    "            average_acute_speed_change_P01 = np.mean(list_of_acute_speed_crossing_inside_P01)\n",
    "            averaged_list_of_acute_speed_crossing_inside_P01.append(average_acute_speed_change_P01)\n",
    "        else:\n",
    "            averaged_list_of_acute_speed_crossing_inside_P01.append(np.nan)\n",
    "\n",
    "        ## go thru the headX coords and detect border crossings\n",
    "        ## every time detect a cross, send the index to the calculateAcuteSpeed function\n",
    "        ## for P10 epoch\n",
    "        for i in range(len(headX_during_P10)-1):\n",
    "            current_coor = headX_during_P10[i]\n",
    "            next_coor = headX_during_P10[i+1]\n",
    "\n",
    "            ## only when crossing inside            \n",
    "            if (current_coor > border_P10) & (next_coor < border_P10):\n",
    "                acute_speed_change_crossing_inside_P10 = calculateAcuteSpeed(headX_during_P10, crossing_idx = i, fps = fps, mmPerPix = mmPerPix, length_sec = 3)\n",
    "                list_of_acute_speed_crossing_inside_P10.append(acute_speed_change_crossing_inside_P10)\n",
    "\n",
    "        ## Since each fly can have multiple border crossings and hence acute speeds,I get the average per fly.\n",
    "        if list_of_acute_speed_crossing_inside_P10 > 0:\n",
    "            average_acute_speed_change_P10 = np.mean(list_of_acute_speed_crossing_inside_P10)\n",
    "            averaged_list_of_acute_speed_crossing_inside_P10.append(average_acute_speed_change_P10)\n",
    "        else:\n",
    "            averaged_list_of_acute_speed_crossing_inside_P10.append(np.nan)\n",
    "\n",
    "\n",
    "    df = df.assign(SpeedCrossingInside_P01 = pd.Series(averaged_list_of_acute_speed_crossing_inside_P01, index=df.index),\n",
    "                   SpeedCrossingInside_P10 = pd.Series(averaged_list_of_acute_speed_crossing_inside_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(SpeedCrossingInside_Mean = pd.Series(df[['SpeedCrossingInside_P01','SpeedCrossingInside_P10']].mean(axis=1), index=df.index))\n",
    "    plotTheMetric(df,'SpeedCrossingInside',rootDir,combineControls,dropNans)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: Speed crossing outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NTS: CHANGE to SMOOTHED HEADX\n",
    "def calculateAcuteSpeed(data, crossing_idx, fps, mmPerPix, length_sec=3):\n",
    "    sec_to_frames = length_sec * fps\n",
    "    crossing_phase = data[crossing_idx:crossing_idx+sec_to_frames]\n",
    "    \n",
    "    total_distance_pix = np.sum(np.absolute(np.diff(crossing_phase)))\n",
    "    total_distance_mm = total_distance_pix * mmPerPix\n",
    "\n",
    "    acute_speed_pix_per_frame = float(total_distance_pix)/float(sec_to_frames)\n",
    "    acute_speed_mm_per_sec = float(total_distance_mm)/float(length_sec)\n",
    "    \n",
    "    return acute_speed_mm_per_sec\n",
    "\n",
    "def SpeedCrossingOutside(df, rootDir, combineControls=False, dropNans=False):\n",
    "    ## lists to keep the metric for each fly\n",
    "    averaged_list_of_acute_speed_crossing_outside_P01 = []\n",
    "    averaged_list_of_acute_speed_crossing_outside_P10 = []\n",
    "\n",
    "    for fly in range(len(df)):\n",
    "        ## lists to keep the metric for each fly\n",
    "        list_of_acute_speed_crossing_outside_P01 = []\n",
    "        list_of_acute_speed_crossing_outside_P10 = []\n",
    "\n",
    "        ## get the P01 and P10 epoch indices\n",
    "        start_of_P01 = df['LightON index|P01'][fly][0]\n",
    "        end_of_P01 = df['LightON index|P01'][fly][1]\n",
    "\n",
    "        start_of_P10 = df['LightON index|P10'][fly][0]\n",
    "        end_of_P10 = df['LightON index|P10'][fly][1]\n",
    "\n",
    "        ## get the head X positions during the epochs\n",
    "        headX_during_P01 = df['HeadX(pix)_smoothed'][fly][start_of_P01:end_of_P01]\n",
    "        headX_during_P10 = df['HeadX(pix)_smoothed'][fly][start_of_P10:end_of_P10]\n",
    "\n",
    "        ## get the border corrdinates\n",
    "        border_P01 = df['Border|P01'][fly]\n",
    "        border_P10 = df['Border|P10'][fly]\n",
    "\n",
    "        ## get the fps for acute speed calculations\n",
    "        fps = df['fps'][fly]\n",
    "        mmPerPix = df['mmPerPix'][fly]\n",
    "\n",
    "        ## go thru the headX coords and detect border crossings\n",
    "        ## every time detect a cross, send the index to the calculateAcuteSpeed function\n",
    "        ## for P01 epoch\n",
    "        for i in range(len(headX_during_P01)-1):\n",
    "            current_coor = headX_during_P01[i]\n",
    "            next_coor = headX_during_P01[i+1]\n",
    "\n",
    "            ## only when crossing outside            \n",
    "            if (current_coor > border_P01) & (next_coor < border_P01):\n",
    "                acute_speed_change_crossing_outside_P01 = calculateAcuteSpeed(headX_during_P01, crossing_idx = i, fps = fps, mmPerPix = mmPerPix, length_sec = 3)\n",
    "                list_of_acute_speed_crossing_outside_P01.append(acute_speed_change_crossing_outside_P01)\n",
    "\n",
    "        ## Since each fly can have multiple border crossings and hence acute speeds,I get the average per fly.\n",
    "        if list_of_acute_speed_crossing_outside_P01 > 0:\n",
    "            average_acute_speed_change_P01 = np.mean(list_of_acute_speed_crossing_outside_P01)\n",
    "            averaged_list_of_acute_speed_crossing_outside_P01.append(average_acute_speed_change_P01)\n",
    "        else:\n",
    "            averaged_list_of_acute_speed_crossing_outside_P01.append(np.nan)\n",
    "\n",
    "        ## go thru the headX coords and detect border crossings\n",
    "        ## every time detect a cross, send the index to the calculateAcuteSpeed function\n",
    "        ## for P10 epoch\n",
    "        for i in range(len(headX_during_P10)-1):\n",
    "            current_coor = headX_during_P10[i]\n",
    "            next_coor = headX_during_P10[i+1]\n",
    "\n",
    "            ## only when crossing outside            \n",
    "            if (current_coor < border_P10) & (next_coor > border_P10):\n",
    "                acute_speed_change_crossing_outside_P10 = calculateAcuteSpeed(headX_during_P10, crossing_idx = i, fps = fps, mmPerPix = mmPerPix, length_sec = 3)\n",
    "                list_of_acute_speed_crossing_outside_P10.append(acute_speed_change_crossing_outside_P10)\n",
    "\n",
    "        ## Since each fly can have multiple border crossings and hence acute speeds,I get the average per fly.\n",
    "        if list_of_acute_speed_crossing_outside_P10 > 0:\n",
    "            average_acute_speed_change_P10 = np.mean(list_of_acute_speed_crossing_outside_P10)\n",
    "            averaged_list_of_acute_speed_crossing_outside_P10.append(average_acute_speed_change_P10)\n",
    "        else:\n",
    "            averaged_list_of_acute_speed_crossing_outside_P10.append(np.nan)\n",
    "\n",
    "\n",
    "    df = df.assign(SpeedCrossingOutside_P01 = pd.Series(averaged_list_of_acute_speed_crossing_outside_P01, index=df.index),\n",
    "                   SpeedCrossingOutside_P10 = pd.Series(averaged_list_of_acute_speed_crossing_outside_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(SpeedCrossingOutside_Mean = pd.Series(df[['SpeedCrossingOutside_P01','SpeedCrossingOutside_P10']].mean(axis=1), index=df.index))\n",
    "    plotTheMetric(df,'SpeedCrossingOutside',rootDir,combineControls,dropNans)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Queue\n",
    "\n",
    "### Stop probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plot a single fly's trajectory as well as first light contacts.\n",
    "def VisualizeSingleFlyTrajectory(df,flyiLoc,mark =False, smoothHeadX = False, speed= False):\n",
    "    singleFlyData = df.iloc[flyiLoc,:]\n",
    "\n",
    "    ## Get the data for the selected fly\n",
    "    genotype = singleFlyData['Genotype']\n",
    "    lightON_P01,lightOFF_P01 = singleFlyData['LightON index|P01'][0],singleFlyData['LightON index|P01'][1]\n",
    "    lightON_P10,lightOFF_P10 = singleFlyData['LightON index|P10'][0],singleFlyData['LightON index|P10'][1]\n",
    "    if (smoothHeadX == False):\n",
    "        headXData = singleFlyData['HeadX(pix)']\n",
    "    elif (smoothHeadX == True):\n",
    "        headXData = singleFlyData['HeadX(pix)_smoothed']\n",
    "    \n",
    "    ## If no contact with light, assign 0\n",
    "    firstLightContact_P01 = int(singleFlyData['First light contact index_of_the_whole_data|P01']) if math.isnan(singleFlyData['First light contact index_of_the_whole_data|P01']) == False else 0\n",
    "    firstLightContact_P10 = int(singleFlyData['First light contact index_of_the_whole_data|P10']) if math.isnan(singleFlyData['First light contact index_of_the_whole_data|P10']) == False else 0\n",
    "    border_P01 = singleFlyData['Border|P01']\n",
    "    border_P10 = singleFlyData['Border|P10']\n",
    "    ChoiceZoneBorders_P01 = singleFlyData['ChoiceZoneBordersperFly_P01']\n",
    "    ChoiceZoneBorders_P10 = singleFlyData['ChoiceZoneBordersperFly_P10']\n",
    "    \n",
    "    ## Open a new figure\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    ax1 = plt.subplot(111)\n",
    "\n",
    "    if speed == True:\n",
    "        speed = np.absolute(np.diff(headXData))\n",
    "        ax1.plot(range(len(speed)), speed, color='black')\n",
    "        \n",
    "        normalized_border_P01 = border_P01/145.0\n",
    "        normalized_border_P10 = border_P10/145.0\n",
    "        \n",
    "        ax1.axvspan(lightON_P01, lightOFF_P01, ymin = normalized_border_P01, ymax = 1, color='red', alpha=0.3)\n",
    "        ax1.axvspan(lightON_P10, lightOFF_P10, ymin = 0, ymax = normalized_border_P10, color='red', alpha=0.3)\n",
    "        ax1.set_ylabel('Absolute Speed')\n",
    "        ax1.set_xlabel('Time frames')\n",
    "    else:\n",
    "        ax1.plot(range(len(headXData)), headXData, color='black')\n",
    "\n",
    "        ## Normalize borders to a range between 0-1 for the axvspan function\n",
    "        normalized_border_P01 = border_P01/145.0\n",
    "        normalized_border_P10 = border_P10/145.0\n",
    "\n",
    "        ax1.axvspan(lightON_P01, lightOFF_P01, ymin = normalized_border_P01, ymax = 1, color='red', alpha=0.3)\n",
    "        ax1.axvspan(lightON_P10, lightOFF_P10, ymin = 0, ymax = normalized_border_P10, color='red', alpha=0.3)\n",
    "        if firstLightContact_P01 != 0:\n",
    "            ax1.annotate('first' +'\\n'+ 'contact', xy=(firstLightContact_P01, headXData[firstLightContact_P01]), \n",
    "                     xytext=(firstLightContact_P01,headXData[firstLightContact_P01]), arrowprops=dict(facecolor='blue', shrink=0.05))\n",
    "\n",
    "        if firstLightContact_P10 != 0:\n",
    "            ax1.annotate('first' +'\\n'+ 'contact', xy=(firstLightContact_P10, headXData[firstLightContact_P10]), \n",
    "                     xytext=(firstLightContact_P10,headXData[firstLightContact_P10]), arrowprops=dict(facecolor='blue', shrink=0.05))\n",
    "\n",
    "        ax1.axhline(y=ChoiceZoneBorders_P01[0],xmin=.195,xmax=.42,color='red')        \n",
    "        ax1.axhline(y=ChoiceZoneBorders_P01[1],xmin=.195,xmax=.42,color='red')\n",
    "        ax1.axhline(y=ChoiceZoneBorders_P10[0],xmin=.575,xmax=.80,color='red')        \n",
    "        ax1.axhline(y=ChoiceZoneBorders_P10[1],xmin=.575,xmax=.80,color='red')\n",
    "\n",
    "        if mark != False:\n",
    "            ax1.axvline(mark, color = 'blue')\n",
    "        ax1.set_ylim(0,146)\n",
    "        ax1.set_ylabel('HeadX (pix)')\n",
    "        ax1.set_xlabel('Time frames')\n",
    "        sns.set(style=\"ticks\", palette=\"bright\", color_codes=True)\n",
    "        sns.despine()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flyiLoc = 25\n",
    "VisualizeSingleFlyTrajectory(dd, flyiLoc=flyiLoc,mark = False, smoothHeadX=False,speed=False)\n",
    "# plt.savefig('ContactedLight_bothHalves.pdf',dpi=1000,bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VisualizeGroupsOfData(group,data,counter,numOfGroups,axs,individualFlies,durationAfterEntrance_frames,ylim):\n",
    "    \n",
    "    if individualFlies == None:\n",
    "        meanBorder_P01 = np.mean(np.asanyarray(data['Border|P01'].tolist()),axis=0)\n",
    "        meanBorder_P10 = np.mean(np.asanyarray(data['Border|P10'].tolist()),axis=0)\n",
    "        meanChoiceZoneBorders_P01 = np.mean(np.asanyarray(data['ChoiceZoneBordersperFly_P01'].tolist()),axis=0)\n",
    "        meanChoiceZoneBorders_P10 = np.mean(np.asanyarray(data['ChoiceZoneBordersperFly_P10'].tolist()),axis=0)\n",
    "        \n",
    "        #if mean == False:\n",
    "        for fly in range(len(data)):\n",
    "            singleFlyDf = data.iloc[fly]\n",
    "            singleFlyHeadX = singleFlyDf['HeadX(pix)']\n",
    "\n",
    "            singleFlyEntranceData_TheWindSide_P01 = singleFlyDf['FromTheWindPortEnd_P01_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheWindSide_P01 = [item[0] for item in singleFlyEntranceData_TheWindSide_P01 if item]\n",
    "\n",
    "            for index in singleFlyEntranceIndexList_TheWindSide_P01:\n",
    "                axs[counter+0].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = .6, color='black')\n",
    "\n",
    "            singleFlyEntranceData_TheClosedSide_P01 = singleFlyDf['FromTheClosedEnd_P01_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheClosedSide_P01 = [item[0] for item in singleFlyEntranceData_TheClosedSide_P01 if item]\n",
    "\n",
    "            for index in singleFlyEntranceIndexList_TheClosedSide_P01:\n",
    "                axs[counter+numOfGroups].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = .6, color='black')\n",
    "\n",
    "            singleFlyEntranceData_TheWindSide_P10 = singleFlyDf['FromTheWindPortEnd_P10_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheWindSide_P10 = [item[0] for item in singleFlyEntranceData_TheWindSide_P10 if item]\n",
    "\n",
    "            for index in singleFlyEntranceIndexList_TheWindSide_P10:\n",
    "                axs[counter+2*numOfGroups].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = .6, color='black')\n",
    "\n",
    "            singleFlyEntranceData_TheClosedSide_P10 = singleFlyDf['FromTheClosedEnd_P10_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheClosedSide_P10 = [item[0] for item in singleFlyEntranceData_TheClosedSide_P10 if item]\n",
    "\n",
    "            for index in singleFlyEntranceIndexList_TheClosedSide_P10:\n",
    "                axs[counter+3*numOfGroups].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = .6, color='black')\n",
    "\n",
    "        fontdict = {'fontsize':12}\n",
    "        axs[counter+0].set_title('P01_from Wind End| %s' %(group),fontdict=fontdict)        \n",
    "        axs[counter+0].axhline(meanChoiceZoneBorders_P01[0],color='grey')        \n",
    "        axs[counter+0].axhline(meanChoiceZoneBorders_P01[1],color='grey')\n",
    "        axs[counter+0].axhspan(meanBorder_P01,145,color='red',alpha = 0.3)\n",
    "        axs[counter+0].set_ylim(ylim[0],ylim[1])\n",
    "\n",
    "        axs[counter+numOfGroups].set_title('P01_from Closed End| %s' %(group),fontdict=fontdict)\n",
    "        axs[counter+numOfGroups].axhline(meanChoiceZoneBorders_P01[0],color='grey')\n",
    "        axs[counter+numOfGroups].axhline(meanChoiceZoneBorders_P01[1],color='grey') \n",
    "        axs[counter+numOfGroups].axhspan(meanBorder_P01,145,color='red',alpha = 0.3)\n",
    "        axs[counter+numOfGroups].set_ylim(ylim[0],ylim[1])\n",
    "\n",
    "        axs[counter+2*numOfGroups].set_title('P10_from Wind End| %s' %(group),fontdict=fontdict)\n",
    "        axs[counter+2*numOfGroups].axhline(meanChoiceZoneBorders_P10[0],color='grey')\n",
    "        axs[counter+2*numOfGroups].axhline(meanChoiceZoneBorders_P10[1],color='grey') \n",
    "        axs[counter+2*numOfGroups].axhspan(0,meanBorder_P10,color='red',alpha = 0.3)\n",
    "        axs[counter+2*numOfGroups].set_ylim(ylim[0],ylim[1])\n",
    "\n",
    "        axs[counter+3*numOfGroups].set_title('P10_from Closed End| %s' %(group),fontdict=fontdict)\n",
    "        axs[counter+3*numOfGroups].axhline(meanChoiceZoneBorders_P10[0],color='grey')\n",
    "        axs[counter+3*numOfGroups].axhline(meanChoiceZoneBorders_P10[1],color='grey')\n",
    "        axs[counter+3*numOfGroups].axhspan(0,meanBorder_P10,color='red',alpha = 0.3)\n",
    "        axs[counter+3*numOfGroups].set_ylim(ylim[0],ylim[1])\n",
    "            \n",
    "        #elif mean == True:\n",
    "            \n",
    "            \n",
    "        \n",
    "    elif individualFlies != None:\n",
    "        \n",
    "        counter = 0\n",
    "        numOfflies = individualFlies[1] - individualFlies[0]\n",
    "        for fly in range(individualFlies[0],individualFlies[1]):   \n",
    "            \n",
    "            singleFlyDf = data.iloc[fly]\n",
    "            singleFlyHeadX = singleFlyDf['HeadX(pix)']\n",
    "            genotype = singleFlyDf['Genotype']\n",
    "            flyID = singleFlyDf['Fly ID']\n",
    "            \n",
    "            Border_P01 = singleFlyDf['Border|P01']\n",
    "            Border_P10 = singleFlyDf['Border|P10']\n",
    "            ChoiceZoneBorders_P01 = singleFlyDf['ChoiceZoneBordersperFly_P01']\n",
    "            ChoiceZoneBorders_P10 = singleFlyDf['ChoiceZoneBordersperFly_P10']\n",
    "        \n",
    "            singleFlyEntranceData_TheWindSide_P01 = singleFlyDf['FromTheWindPortEnd_P01_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheWindSide_P01 = [item[0] for item in singleFlyEntranceData_TheWindSide_P01 if item]\n",
    "            \n",
    "            linewidth = 1 + 0.8*(numOfflies-1)\n",
    "            for index in singleFlyEntranceIndexList_TheWindSide_P01:\n",
    "                axs[counter*4+0].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = linewidth, color='black')\n",
    "\n",
    "            singleFlyEntranceData_TheClosedSide_P01 = singleFlyDf['FromTheClosedEnd_P01_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheClosedSide_P01 = [item[0] for item in singleFlyEntranceData_TheClosedSide_P01 if item]\n",
    "\n",
    "            for index in singleFlyEntranceIndexList_TheClosedSide_P01:\n",
    "                axs[counter*4+1].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = linewidth, color='black')\n",
    "\n",
    "            singleFlyEntranceData_TheWindSide_P10 = singleFlyDf['FromTheWindPortEnd_P10_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheWindSide_P10 = [item[0] for item in singleFlyEntranceData_TheWindSide_P10 if item]\n",
    "\n",
    "            for index in singleFlyEntranceIndexList_TheWindSide_P10:\n",
    "                axs[counter*4+2].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = linewidth, color='black')\n",
    "\n",
    "            singleFlyEntranceData_TheClosedSide_P10 = singleFlyDf['FromTheClosedEnd_P10_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheClosedSide_P10 = [item[0] for item in singleFlyEntranceData_TheClosedSide_P10 if item]\n",
    "\n",
    "            for index in singleFlyEntranceIndexList_TheClosedSide_P10:\n",
    "                axs[counter*4+3].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = linewidth, color='black')\n",
    "\n",
    "            fontdict = {'fontsize':12*(numOfGroups/1.2)}\n",
    "            axs[counter*4+0].set_title('%s, ID: %s|P01_from Wind End' %(genotype,flyID),fontdict=fontdict)        \n",
    "            axs[counter*4+0].axhline(ChoiceZoneBorders_P01[0],color='grey')        \n",
    "            axs[counter*4+0].axhline(ChoiceZoneBorders_P01[1],color='grey')\n",
    "            axs[counter*4+0].axhspan(Border_P01,145,color='red',alpha = 0.3)\n",
    "            axs[counter*4+0].set_ylim(ylim[0],ylim[1])\n",
    "\n",
    "            axs[counter*4+1].set_title('P01_from Closed End',fontdict=fontdict)\n",
    "            axs[counter*4+1].axhline(ChoiceZoneBorders_P01[0],color='grey')\n",
    "            axs[counter*4+1].axhline(ChoiceZoneBorders_P01[1],color='grey') \n",
    "            axs[counter*4+1].axhspan(Border_P01,145,color='red',alpha = 0.3)\n",
    "            axs[counter*4+1].set_ylim(ylim[0],ylim[1])\n",
    "\n",
    "            axs[counter*4+2].set_title('P10_from Wind End',fontdict=fontdict)\n",
    "            axs[counter*4+2].axhline(ChoiceZoneBorders_P10[0],color='grey')\n",
    "            axs[counter*4+2].axhline(ChoiceZoneBorders_P10[1],color='grey') \n",
    "            axs[counter*4+2].axhspan(0,Border_P10,color='red',alpha = 0.3)\n",
    "            axs[counter*4+2].set_ylim(ylim[0],ylim[1])\n",
    "\n",
    "            axs[counter*4+3].set_title('P10_from Closed End',fontdict=fontdict)\n",
    "            axs[counter*4+3].axhline(ChoiceZoneBorders_P10[0],color='grey')\n",
    "            axs[counter*4+3].axhline(ChoiceZoneBorders_P10[1],color='grey')\n",
    "            axs[counter*4+3].axhspan(0,Border_P10,color='red',alpha = 0.3)\n",
    "            axs[counter*4+3].set_ylim(ylim[0],ylim[1])\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "    return axs\n",
    "\n",
    "def VisualizeTheChoiceZoneTrajectories(df, individualFlies = None, groupBy = None, groupsToPlot = None, durationAfterEntrance_frames=50, \n",
    "                                       mean = False, CI = 95, hspace = .3, wspace = .3, ylim = [30,110]):\n",
    "   \n",
    "    if individualFlies == None:\n",
    "        #if mean == False:\n",
    "        if groupsToPlot == None:    \n",
    "            df_grouped = df.groupby(groupBy)\n",
    "            numOfGroups = len(df_grouped)\n",
    "            figSize = (5*numOfGroups,20)\n",
    "            fig, axs = plt.subplots(4,numOfGroups, figsize=figSize, facecolor='w', edgecolor='k')\n",
    "            fig.subplots_adjust(hspace = hspace, wspace = wspace)\n",
    "            axs = axs.ravel()\n",
    "\n",
    "            counter = 0\n",
    "\n",
    "            ## for each group of flies (i.e, parent vs offspring), I'm going to plot 4 types of decision zone trajectories:\n",
    "            ## P01: entrance from wind AND closed end, P10: entrance from wind AND closed end\n",
    "            for group,data in df_grouped:\n",
    "                axs = VisualizeGroupsOfData(group,data,counter,numOfGroups,axs,individualFlies,durationAfterEntrance_frames,ylim)\n",
    "                counter += 1\n",
    "\n",
    "        else:    \n",
    "            df_grouped = df.groupby(groupBy)\n",
    "            numOfGroups = len(groupsToPlot)\n",
    "            figSize = (5*numOfGroups,20)\n",
    "            fig, axs = plt.subplots(4,numOfGroups, figsize=figSize, facecolor='w', edgecolor='k')\n",
    "            fig.subplots_adjust(hspace = hspace, wspace = wspace)\n",
    "            axs = axs.ravel()  \n",
    "\n",
    "            counter = 0\n",
    "            for group in groupsToPlot:\n",
    "                data = df_grouped.get_group(group)\n",
    "                axs = VisualizeGroupsOfData(group,data,counter,numOfGroups,axs,individualFlies,durationAfterEntrance_frames,ylim)\n",
    "                counter += 1\n",
    "        \n",
    "        #elif mean == True:\n",
    "            \n",
    "            \n",
    "    \n",
    "    elif individualFlies != None:\n",
    "        group = None\n",
    "        counter = None\n",
    "        \n",
    "        numOfGroups = individualFlies[1] - individualFlies[0]\n",
    "        figSize = (12*numOfGroups,4*numOfGroups**2)\n",
    "        fig, axs = plt.subplots(numOfGroups,4, figsize=figSize, facecolor='w', edgecolor='k')\n",
    "        fig.subplots_adjust(hspace = hspace, wspace = wspace)\n",
    "        axs = axs.ravel() \n",
    "        \n",
    "        axs = VisualizeGroupsOfData(group,df,counter,numOfGroups,axs,individualFlies,durationAfterEntrance_frames,ylim)\n",
    "        \n",
    "    sns.set(style=\"ticks\", palette=\"bright\", color_codes=True)\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "VisualizeTheChoiceZoneTrajectories(d, individualFlies = [5,6], groupBy = 'Genotype', groupsToPlot = None,\n",
    "                                   durationAfterEntrance_frames = 30, mean=False, CI = 95, hspace = .3,\n",
    "                                   wspace = .3, ylim = [80,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d['FromTheClosedEnd_P01_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d['ChoiceZoneBordersperFly_P01'][5]\n",
    "ChoiceZoneBorders_P01 = d['ChoiceZoneBordersperFly_P01'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = d['HeadX(pix)'][5][1045:1075]\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = plt.subplot(111)\n",
    "ax1.axhline(ChoiceZoneBorders_P01[0],color='grey')\n",
    "ax1.axhline(ChoiceZoneBorders_P01[1],color='grey')\n",
    "\n",
    "ax1.plot(range(len(x)), x, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot any given metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotTheMetric(df,metric,rootDir,combineControls, dropNans=False):\n",
    "    \n",
    "    ## open new folders to save the results\n",
    "    \n",
    "    newFolderName = rootDir + '/' + metric\n",
    "    if not os.path.exists(newFolderName):\n",
    "        os.makedirs(newFolderName)\n",
    "        \n",
    "    newFolderName = rootDir + '/' + metric + '/P01'\n",
    "    if not os.path.exists(newFolderName):\n",
    "        os.makedirs(newFolderName)\n",
    "        \n",
    "    newFolderName = rootDir + '/' + metric + '/P10'\n",
    "    if not os.path.exists(newFolderName):\n",
    "        os.makedirs(newFolderName)\n",
    "    \n",
    "    newFolderName = rootDir + '/' + metric + '/Mean'\n",
    "    if not os.path.exists(newFolderName):\n",
    "        os.makedirs(newFolderName)\n",
    "    \n",
    "    ## Save the df which contains the quantitative values of the given metrics, in case I need to plot them again\n",
    "    savePath = rootDir + '/' + metric + '/'\n",
    "    df.to_pickle(savePath + metric + '_values.pkl')\n",
    "    \n",
    "    ## define the color palette\n",
    "    myPal = {df['Genotype'].unique()[0] : 'lightgreen',\n",
    "             df['Genotype'].unique()[1] : 'cyan',\n",
    "             df['Genotype'].unique()[2]:  'red'}\n",
    "    \n",
    "    ## get the list of vairables    \n",
    "    listofSex = df['Sex'].unique()\n",
    "    listofSatiety = df['Satiety'].unique()\n",
    "    listofWindStat = df['Wind status'].unique()\n",
    "    listofGenotypes = df['Genotype'].unique()\n",
    "        \n",
    "    ## if combineControls is true, then status-based df, else genotype-based.\n",
    "    if combineControls == True:\n",
    "        \n",
    "        ## make the columns to classify data points  (status-based in this case)\n",
    "        df = df.assign(Status_Sex_Satiety_LightType_Intensity_Wind = pd.Series(df['Status'] + '_' + df['Sex'] + '_' +\n",
    "             df['Satiety'] + '_' + df['Light type'] + '_' + df['Light Intensity(uW/mm2)'] + '_' +\n",
    "             df['Wind status'], index = df.index))  \n",
    "        \n",
    "        ## going to generate plots for each of the combination of these three condition, i.e, male_fed__NoAir\n",
    "        for sex in listofSex:\n",
    "            for satietyStat in listofSatiety:\n",
    "                for windStat in listofWindStat:\n",
    "                    \n",
    "                    ## I wanted to keep the original metric name to access the columns in the df.\n",
    "                    ## Generating the new variable, metricForFileName, helps me to specify whether the nans were dropped\n",
    "                    ## in the file name.\n",
    "                    if dropNans == False:\n",
    "                        metricForFileName = metric + '_CombinedControls'\n",
    "                    elif dropNans == True:\n",
    "                        metricForFileName = metric + '_CombinedControls_NansDropped'\n",
    "                        \n",
    "                    ## P01 of the metric\n",
    "                    fig,b = bs.contrastplot(df, x = 'Status_Sex_Satiety_LightType_Intensity_Wind', y = metric+'_P01' ,\n",
    "                            color_col= 'Genotype', custom_palette = myPal,  float_contrast=False,                     \n",
    "                          idx = (\n",
    "                                 ('Parent_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat)),\n",
    "                                 ('Parent_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat)),\n",
    "                                 ('Parent_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_'+ str(windStat)))\n",
    "                                                                  )\n",
    "                    savePath = rootDir + '/' + metric + '/P01/'\n",
    "                    saveFileName = metricForFileName + '_P01_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "                    \n",
    "                    ## close the figures to save memory\n",
    "                    plt.close(fig)\n",
    "                    plt.clf()\n",
    "\n",
    "                    ## P10 of the metric\n",
    "                    fig,b = bs.contrastplot(df, x = 'Status_Sex_Satiety_LightType_Intensity_Wind', y = metric+'_P10' ,\n",
    "                            color_col= 'Genotype', custom_palette = myPal,  float_contrast=False,                     \n",
    "                          idx = (\n",
    "                                 ('Parent_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat)),\n",
    "                                 ('Parent_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat)),\n",
    "                                 ('Parent_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_'+ str(windStat)))\n",
    "                                                                  )\n",
    "                    savePath = rootDir + '/' + metric + '/P10/'\n",
    "                    saveFileName = metricForFileName + '_P10_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "                                               \n",
    "                    plt.close(fig)\n",
    "                    plt.clf()\n",
    "\n",
    "                    ## Mean of the metric\n",
    "                    fig,b = bs.contrastplot(df, x = 'Status_Sex_Satiety_LightType_Intensity_Wind', y = metric+'_Mean' ,\n",
    "                            color_col= 'Genotype', custom_palette = myPal, float_contrast=False,                     \n",
    "                          idx = (\n",
    "                                 ('Parent_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat)),\n",
    "                                 ('Parent_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat)),\n",
    "                                 ('Parent_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_'+ str(windStat)))\n",
    "                                                                  )\n",
    "                    savePath = rootDir + '/' + metric + '/Mean/'\n",
    "                    saveFileName = metricForFileName + '_Mean_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "                    plt.close(fig)\n",
    "                    plt.clf()\n",
    "    \n",
    "    elif combineControls == False:  \n",
    "        ## generate the columns to callsify the data points, this time genotype-based\n",
    "        df = df.assign(Genotype_Sex_Satiety_LightType_Intensity_Wind = pd.Series(df['Genotype'] + '_' + df['Sex'] + '_' +\n",
    "             df['Satiety'] + '_' + df['Light type'] + '_' + df['Light Intensity(uW/mm2)'] + '_' +\n",
    "             df['Wind status'], index = df.index))\n",
    "        \n",
    "        ## going to generate plots for each of the combination of these three condition, i.e, male_fed__NoAir\n",
    "        for sex in listofSex:\n",
    "            for satietyStat in listofSatiety:\n",
    "                for windStat in listofWindStat:\n",
    "                    \n",
    "                    ## I wanted to keep the original metric name to access the columns in the df.\n",
    "                    ## Generating the new variable, metricForFileName, helps me to specify whether the nans were dropped\n",
    "                    ## in the file name.\n",
    "                    if dropNans == False:\n",
    "                        metricForFileName = metric\n",
    "                    elif dropNans == True:\n",
    "                        metricForFileName = metric + '_NansDropped'\n",
    "                        \n",
    "                    ## P01 of the metric\n",
    "                    fig,b = bs.contrastplot(df, x = 'Genotype_Sex_Satiety_LightType_Intensity_Wind', y = metric+'_P01' ,\n",
    "                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                          idx = (\n",
    "                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat), \n",
    "                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat),\n",
    "                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat)),\n",
    "                              \n",
    "                                  (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat), \n",
    "                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat),\n",
    "                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat)),\n",
    "                                  \n",
    "                                  (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_' + str(windStat), \n",
    "                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_' + str(windStat),\n",
    "                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_' + str(windStat))))\n",
    "                        \n",
    "                    savePath = rootDir + '/' + metric + '/P01/'\n",
    "                    saveFileName = metricForFileName + '_P01_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                    plt.savefig(savePath + saveFileName + '.pdf',dpi=1000,bbox_inches='tight')\n",
    "                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "                    \n",
    "                    ## close the figures to save memory\n",
    "                    plt.close(fig)\n",
    "                    plt.clf()\n",
    "\n",
    "                    \n",
    "                    ## P10 of the metric\n",
    "                    fig,b = bs.contrastplot(df, x = 'Genotype_Sex_Satiety_LightType_Intensity_Wind', y = metric+'_P10' ,\n",
    "                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                          idx = (\n",
    "                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat), \n",
    "                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat),\n",
    "                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat)),\n",
    "                              \n",
    "                                  (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat), \n",
    "                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat),\n",
    "                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat)),\n",
    "                                  \n",
    "                                  (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_' + str(windStat), \n",
    "                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_' + str(windStat),\n",
    "                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_' + str(windStat))))\n",
    "                        \n",
    "                    savePath = rootDir + '/' + metric + '/P10/'\n",
    "                    saveFileName = metricForFileName + '_P10_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                    plt.savefig(savePath + saveFileName + '.pdf',dpi=1000,bbox_inches='tight')\n",
    "                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "                    \n",
    "                    ## close the figures to save memory\n",
    "                    plt.close(fig)\n",
    "                    plt.clf()\n",
    "                    \n",
    "                    ## Mean of the metric\n",
    "                    fig,b = bs.contrastplot(df, x = 'Genotype_Sex_Satiety_LightType_Intensity_Wind', y = metric+'_Mean' ,\n",
    "                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                          idx = (\n",
    "                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat), \n",
    "                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat),\n",
    "                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_14uW_' + str(windStat)),\n",
    "                              \n",
    "                                  (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat), \n",
    "                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat),\n",
    "                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_42uW_' + str(windStat)),\n",
    "                                  \n",
    "                                  (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_' + str(windStat), \n",
    "                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_' + str(windStat),\n",
    "                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_Constant_70uW_' + str(windStat))))\n",
    "                        \n",
    "                    savePath = rootDir + '/' + metric + '/Mean/'\n",
    "                    saveFileName = metricForFileName + '_Mean_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                    plt.savefig(savePath + saveFileName + '.pdf',dpi=1000,bbox_inches='tight')\n",
    "                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "                    \n",
    "                    ## close the figures to save memory\n",
    "                    plt.close(fig)\n",
    "                    plt.clf()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "# %matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import bootstrap_contrast as bs\n",
    "from nptdms import *\n",
    "import math\n",
    "from collections import Counter\n",
    "import shutil\n",
    "import progressbar\n",
    "\n",
    "# rootDir = 'C:/Users/tumkayat/Desktop/CodeRep/WALiSAR/BehaviroalDataAnalyses/WALiSuite_v0.1/SampleFolderStructure'\n",
    "# d, t = WALiMe(rootDir=rootDir, metrics = ['TSALE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('C:/Users/tumkayat/Desktop/CodeRep/WALiSAR/BehaviroalDataAnalyses/WALiSuite_v0.1/SampleFolderStructure/Or9a/RawDataFrame.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = df.copy(deep=True)\n",
    "df['Light Intensity(uW/mm2)'] = df['Light Intensity(uW/mm2)'].str[3:-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.assign(Status_Sex_Satiety_LightType_Intensity_Wind = pd.Series(df['Status'] + '_' + df['Sex'] + '_' +\n",
    "             df['Satiety'] + '_' + df['Light type'] + '_' + df['Light Intensity(uW/mm2)'] + '_' +\n",
    "             df['Wind status'], index = df.index))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def WALiMe(rootDirectory):\n",
    "    \n",
    "    ## Get a list of ORNs in the folder\n",
    "    ornList = os.listdir(rootDirectory)\n",
    "        \n",
    "    \n",
    "    for ORN in ornList:\n",
    "        ## read the data in a df\n",
    "        print '%s is in progress...' %(ORN)\n",
    "\n",
    "        rootDir = os.path.join(rootDirectory,ORN)\n",
    "        fileList = os.listdir(rootDir)\n",
    "        \n",
    "        if 'RawDataFrame.pkl' in fileList:\n",
    "            df = pd.read_pickle(rootDir + '/RawDataFrame.pkl')\n",
    "        else:\n",
    "            df = dataToDataframe(rootDir)\n",
    "        ## FIX THIS SHIT\n",
    "        df['Light Intensity(uW/mm2)'] = df['Light Intensity(uW/mm2)'].str[3:-9]\n",
    "\n",
    "        ## apply the metrics\n",
    "        LaXS(df, rootDir, dropNans=False, combineControls=True)\n",
    "        TSALE(df, rootDir, dropNans=False, combineControls=True)\n",
    "        weighted_TSALE(df, rootDir, dropNans=False, combineControls=True)\n",
    "        LAI(df, rootDir, dropNans=False, combineControls=True)\n",
    "        RPI(df, rootDir, dropNans=False, combineControls=True)\n",
    "        DeltaPercentTimeSpent(df, rootDir, dropNans=False, combineControls=True)\n",
    "        Log2SpeedRatio(df, rootDir, dropNans=False, combineControls=True)\n",
    "        SpeedCrossingInside(df, rootDir, dropNans=False, combineControls=True)\n",
    "        SpeedCrossingOutside(df, rootDir, dropNans=False, combineControls=True)\n",
    "        NoBC(df, rootDir, dropNans=False, combineControls=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Or9a is in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tumkayat\\AppData\\Local\\Continuum\\Anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\tumkayat\\AppData\\Local\\Continuum\\Anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "# %matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import bootstrap_contrast as bs\n",
    "from nptdms import *\n",
    "import math\n",
    "from collections import Counter\n",
    "import shutil\n",
    "import progressbar\n",
    "from svgutils.compose import *\n",
    "\n",
    "rootDirectory = 'C:/Users/tumkayat/Desktop/CodeRep/WALiSAR/BehaviroalDataAnalyses/WALiSuite_v0.1/SampleFolderStructure/'\n",
    "d = WALiMe(rootDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine SVG images of all metrics in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rootDir = 'C:/Users/tumkayat/Desktop/CodeRep/WALiSAR/BehaviroalDataAnalyses/WALiSuite_v0.1/SampleFolderStructure/'\n",
    "ornList = os.listdir(rootDir)\n",
    "    \n",
    "epoch_to_combine = 'P10'\n",
    "\n",
    "def combineSVGImages(rootDir,epoch_to_combine):\n",
    "    \n",
    "    for ORN in ornList:\n",
    "        rootDir = os.path.join(rootDir,ORN)\n",
    "\n",
    "        ## Page 1\n",
    "        Figure(\"59.4cm\", \"84.1cm\", \n",
    "               ## LaxS images\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LaXS/\" + epoch_to_combine + \"/LaXS_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"A\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LaXS/\" + epoch_to_combine + \"/LaXS_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 0),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LaXS/\" + epoch_to_combine + \"/LaXS_CombinedControls_\" + epoch_to_combine + \"_male_Starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 21)\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LaXS/\" + epoch_to_combine + \"/LaXS_CombinedControls_\" + epoch_to_combine + \"_male_Starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 21)\n",
    "\n",
    "                ## TSALE images\n",
    "\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/TSALE/\" + epoch_to_combine + \"/TSALE_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"C\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/TSALE/\" + epoch_to_combine + \"/TSALE_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_Air.svg\").scale(0.025),\n",
    "                  Text(\"D\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/TSALE/\" + epoch_to_combine + \"/TSALE_CombinedControls_\" + epoch_to_combine + \"_male_Starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 63)\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/TSALE/\" + epoch_to_combine + \"/TSALE_CombinedControls_\" + epoch_to_combine + \"_male_Starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 63)).save(rootDir+\"/Metrics_Combined_p1\" + epoch_to_combine + \".svg\")\n",
    "\n",
    "\n",
    "        ## Page 2\n",
    "\n",
    "        Figure(\"59.4cm\", \"84.1cm\", \n",
    "               ## weighted TSALE images\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/weighted_TSALE/\" + epoch_to_combine + \"/weighted_TSALE_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"A\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/weighted_TSALE/\" + epoch_to_combine + \"/weighted_TSALE_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 0),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/weighted_TSALE/\" + epoch_to_combine + \"/weighted_TSALE_CombinedControls_\" + epoch_to_combine + \"_male_Starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 21)\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/weighted_TSALE/\" + epoch_to_combine + \"/weighted_TSALE_CombinedControls_\" + epoch_to_combine + \"_male_Starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 21)\n",
    "\n",
    "                ## Light Attraction Index images\n",
    "\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LAI/\" + epoch_to_combine + \"/LAI_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"C\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LAI/\" + epoch_to_combine + \"/LAI_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_Air.svg\").scale(0.025),\n",
    "                  Text(\"D\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LAI/\" + epoch_to_combine + \"/LAI_CombinedControls_\" + epoch_to_combine + \"_male_Starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 63)\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LAI/\" + epoch_to_combine + \"/LAI_CombinedControls_\" + epoch_to_combine + \"_male_Starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 63)).save(rootDir+\"/Metrics_Combined_p2\" + epoch_to_combine + \".svg\")\n",
    "\n",
    "        ## Page 3\n",
    "\n",
    "        Figure(\"59.4cm\", \"84.1cm\", \n",
    "               ## Reversal PI images\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/RPI/\" + epoch_to_combine + \"/RPI_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"A\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/RPI/\" + epoch_to_combine + \"/RPI_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 0),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/RPI/\" + epoch_to_combine + \"/RPI_CombinedControls_\" + epoch_to_combine + \"_male_Starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 21)\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/RPI/\" + epoch_to_combine + \"/RPI_CombinedControls_\" + epoch_to_combine + \"_male_Starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 21)\n",
    "\n",
    "                ## DeltaPercentTimeSpent images\n",
    "\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/DeltaPercentTimeSpent/\" + epoch_to_combine + \"/DeltaPercentTimeSpent_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"C\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/DeltaPercentTimeSpent/\" + epoch_to_combine + \"/DeltaPercentTimeSpent_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_Air.svg\").scale(0.025),\n",
    "                  Text(\"D\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/DeltaPercentTimeSpent/\" + epoch_to_combine + \"/DeltaPercentTimeSpent_CombinedControls_\" + epoch_to_combine + \"_male_Starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 63)\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/DeltaPercentTimeSpent/\" + epoch_to_combine + \"/DeltaPercentTimeSpent_CombinedControls_\" + epoch_to_combine + \"_male_Starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 63)).save(rootDir+\"/Metrics_Combined_p3\" + epoch_to_combine + \".svg\")\n",
    "\n",
    "        ## Page 4\n",
    "\n",
    "        Figure(\"59.4cm\", \"84.1cm\", \n",
    "               ## Log2SpeedRatio images\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/Log2SpeedRatio/\" + epoch_to_combine + \"/Log2SpeedRatio_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"A\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/Log2SpeedRatio/\" + epoch_to_combine + \"/Log2SpeedRatio_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 0),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/Log2SpeedRatio/\" + epoch_to_combine + \"/Log2SpeedRatio_CombinedControls_\" + epoch_to_combine + \"_male_Starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 21)\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/Log2SpeedRatio/\" + epoch_to_combine + \"/Log2SpeedRatio_CombinedControls_\" + epoch_to_combine + \"_male_Starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 21)\n",
    "\n",
    "                ## SpeedCrossingInside images\n",
    "\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingInside/\" + epoch_to_combine + \"/SpeedCrossingInside_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"C\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingInside/\" + epoch_to_combine + \"/SpeedCrossingInside_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_Air.svg\").scale(0.025),\n",
    "                  Text(\"D\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingInside/\" + epoch_to_combine + \"/SpeedCrossingInside_CombinedControls_\" + epoch_to_combine + \"_male_Starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 63)\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingInside/\" + epoch_to_combine + \"/SpeedCrossingInside_CombinedControls_\" + epoch_to_combine + \"_male_Starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 63)).save(rootDir+\"/Metrics_Combined_p4\" + epoch_to_combine + \".svg\")\n",
    "\n",
    "        ## Page 5\n",
    "\n",
    "        Figure(\"59.4cm\", \"84.1cm\", \n",
    "               ## SpeedCrossingOutside images\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingOutside/\" + epoch_to_combine + \"/SpeedCrossingOutside_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"A\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingOutside/\" + epoch_to_combine + \"/SpeedCrossingOutside_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 0),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingOutside/\" + epoch_to_combine + \"/SpeedCrossingOutside_CombinedControls_\" + epoch_to_combine + \"_male_Starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 21)\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingOutside/\" + epoch_to_combine + \"/SpeedCrossingOutside_CombinedControls_\" + epoch_to_combine + \"_male_Starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 21)\n",
    "\n",
    "                ## NoBC images\n",
    "\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/NoBC/\" + epoch_to_combine + \"/NoBC_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"C\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/NoBC/\" + epoch_to_combine + \"/NoBC_CombinedControls_\" + epoch_to_combine + \"_male_Satiated_Air.svg\").scale(0.025),\n",
    "                  Text(\"D\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/NoBC/\" + epoch_to_combine + \"/NoBC_CombinedControls_\" + epoch_to_combine + \"_male_Starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 63)\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/NoBC/\" + epoch_to_combine + \"/NoBC_CombinedControls_\" + epoch_to_combine + \"_male_Starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 63)).save(rootDir+\"/Metrics_Combined_p5\" + epoch_to_combine + \".svg\")\n",
    "    return None\n",
    "    \n",
    "    \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
